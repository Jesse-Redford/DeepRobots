{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ContinuousDeepRobots import ThreeLinkRobot\n",
    "import random\n",
    "import copy\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from math import pi, log\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DQNAgent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-54-3f59fdecb47c>, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-3f59fdecb47c>\"\u001b[0;36m, line \u001b[0;32m80\u001b[0m\n\u001b[0;31m    for action in self.actions:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class DQNAgent:\n",
    "    INPUT_DIM = 5\n",
    "    OUTPUT_DIM = 1\n",
    "    def __init__(self, actions_params=(-pi/16, pi/16, pi/128), memory_size=500, gamma=0.9995, epsilon=1.0, \n",
    "                 epsilon_min=0.01, epsilon_decay=0.995, learning_rate=0.001):\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.gamma = gamma    # discount rate\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.actions = self._get_actions(actions_params)\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _get_actions(self, actions_params):\n",
    "        \"\"\"\n",
    "        :return: a list of action space values in tuple format (a1dot, a2dot)\n",
    "        \"\"\"\n",
    "        lower_limit, upper_limit, interval = actions_params\n",
    "        upper_limit += (interval/10)  # to ensure the range covers the rightmost value in the loop\n",
    "        r = np.arange(lower_limit, upper_limit, interval)\n",
    "        actions = [(i, j) for i in r for j in r]\n",
    "\n",
    "        # remove a1dot = 0, a2dot = 0 from action space\n",
    "        actions.remove((0.0,0.0))\n",
    "\n",
    "        return actions\n",
    "    \n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        # input layer\n",
    "        model.add(Dense(250, input_dim=self.INPUT_DIM, activation='relu'))\n",
    "        # hidden layers\n",
    "        model.add(Dense(500, activation='relu'))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        # output layer\n",
    "        model.add(Dense(self.OUTPUT_DIM, activation = 'linear'))\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state):\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "\n",
    "    def choose_action(self, robot, state, epsilon_greedy=False):\n",
    "        \"\"\"\n",
    "        epsilon-greedy approach for choosing an action and transition into next state\n",
    "        returns the next state, reward resulting from the chosen action\n",
    "        \"\"\"\n",
    "        chosen_action = None\n",
    "        if epsilon_greedy:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                # print('random actions')\n",
    "                # choose random action\n",
    "                while True:\n",
    "                    chosen_action = random.choice(self.actions)\n",
    "                    temp_robot = copy.deepcopy(robot)\n",
    "                    _, a1, a2 = temp_robot.move(chosen_action)\n",
    "                    if a1 - a2 > 0.001 and -pi/2 <= a1 <= pi/2 and -pi/2 <= a2 <= pi/2:\n",
    "                        break\n",
    "            else:\n",
    "                # print('argmax')\n",
    "                # find the action with greatest Q value\n",
    "                maxQ = -float(\"inf\")\n",
    "                for action in self.actions:\n",
    "                    input_data = np.asarray(state + action).reshape(1, 5)\n",
    "                    Q = self.model.predict(input_data)        \n",
    "                    if Q > maxQ:\n",
    "                        temp_robot = copy.deepcopy(robot)\n",
    "                        _, a1, a2 = temp_robot.move(action)\n",
    "                        # print('a1 - a2 > 0.00001: ', a1 - a2 > 0.00001, '-pi/2 <= a1 <= pi/2: ', -pi/2 <= a1 <= pi/2, '-pi/2 <= a2 <= pi/2: ', -pi/2 <= a2 <= pi/2)\n",
    "                        if a1 - a2 > 0.00001 and -pi/2 <= a1 <= pi/2 and -pi/2 <= a2 <= pi/2:\n",
    "                            maxQ = Q\n",
    "                            chosen_action = action\n",
    "        else:\n",
    "            \n",
    "            # policy rollout\n",
    "            maxQ = -float(\"inf\")\n",
    "                for action in self.actions:\n",
    "                    input_data = np.asarray(state + action).reshape(1, 5)\n",
    "                    Q = self.model.predict(input_data)        \n",
    "                    if Q > maxQ:\n",
    "                        maxQ = Q\n",
    "                        chosen_action = action\n",
    "                     \n",
    "        return chosen_action\n",
    "    \n",
    "    def act(self, robot, action):\n",
    "        \n",
    "        # transition into next state\n",
    "        next_state = robot.move(action=action)\n",
    "        \n",
    "        # calculate reward\n",
    "        a1, a2, v, a1dot, a2dot = robot.a1, robot.a2, robot.body_v[0], robot.a1dot, robot.a2dot\n",
    "        reward = v/(a1dot**2 + a2dot**2)\n",
    "        \n",
    "        return robot, reward, next_state\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        losses = []\n",
    "        for state, action, reward, next_state in minibatch:\n",
    "            \n",
    "            # perform Bellman Update (use temporal difference?)\n",
    "            input_data = np.asarray(state + action).reshape(1, 5)\n",
    "            # print('reward: ', reward, 'prediction: ', self.model.predict(input_data))\n",
    "            Q_target = reward + self.gamma * self.model.predict(input_data)\n",
    "            \n",
    "            # perform a gradient descent step\n",
    "            loss = self.model.train_on_batch(input_data, Q_target)\n",
    "            # print('loss: ', loss, 'input: ', input_data, 'Q_target: ', Q_target)\n",
    "            losses.append(loss)\n",
    "            # self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "            \n",
    "        # update epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "        # return the average lost of this experience replay\n",
    "        return sum(losses)/len(losses)\n",
    "        \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepRobots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  1  th episode,  11  th iteration, the average loss is:  496.84675312\n",
      "In  1  th episode,  12  th iteration, the average loss is:  599.033562088\n",
      "In  1  th episode,  13  th iteration, the average loss is:  331.366205502\n",
      "In  1  th episode,  14  th iteration, the average loss is:  478.679350615\n",
      "In  1  th episode,  15  th iteration, the average loss is:  381.334587955\n",
      "In  1  th episode,  16  th iteration, the average loss is:  476.00259428\n",
      "In  1  th episode,  17  th iteration, the average loss is:  174.384111595\n",
      "In  1  th episode,  18  th iteration, the average loss is:  429.908905053\n",
      "In  1  th episode,  19  th iteration, the average loss is:  4654.27657242\n",
      "In  1  th episode,  20  th iteration, the average loss is:  5800.24889798\n",
      "In  1  th episode,  21  th iteration, the average loss is:  1536.54578319\n",
      "In  1  th episode,  22  th iteration, the average loss is:  4613.47976735\n",
      "In  1  th episode,  23  th iteration, the average loss is:  1459.07423659\n",
      "In  1  th episode,  24  th iteration, the average loss is:  4545.46648111\n",
      "In  1  th episode,  25  th iteration, the average loss is:  391.740616035\n",
      "In  1  th episode,  26  th iteration, the average loss is:  1394.45300789\n",
      "In  1  th episode,  27  th iteration, the average loss is:  1291.17457232\n",
      "In  1  th episode,  28  th iteration, the average loss is:  1152.27157644\n",
      "In  1  th episode,  29  th iteration, the average loss is:  8520.57586613\n",
      "In  1  th episode,  30  th iteration, the average loss is:  492.215690708\n",
      "In  1  th episode,  31  th iteration, the average loss is:  435.864585203\n",
      "In  1  th episode,  32  th iteration, the average loss is:  1944.48670974\n",
      "In  1  th episode,  33  th iteration, the average loss is:  4153.63652077\n",
      "In  1  th episode,  34  th iteration, the average loss is:  654.314603424\n",
      "In  1  th episode,  35  th iteration, the average loss is:  3170.66779028\n",
      "In  1  th episode,  36  th iteration, the average loss is:  3883.19077454\n",
      "In  1  th episode,  37  th iteration, the average loss is:  265.47730484\n",
      "In  1  th episode,  38  th iteration, the average loss is:  3749.40784168\n",
      "In  1  th episode,  39  th iteration, the average loss is:  346.391861534\n",
      "In  1  th episode,  40  th iteration, the average loss is:  1340.68997555\n",
      "In  1  th episode,  41  th iteration, the average loss is:  271.406523204\n",
      "In  1  th episode,  42  th iteration, the average loss is:  4130.11204505\n",
      "In  1  th episode,  43  th iteration, the average loss is:  271.991614151\n",
      "In  1  th episode,  44  th iteration, the average loss is:  2629.75598738\n",
      "In  1  th episode,  45  th iteration, the average loss is:  3278.66116343\n",
      "In  1  th episode,  46  th iteration, the average loss is:  438.923083211\n",
      "In  1  th episode,  47  th iteration, the average loss is:  5506.73298035\n",
      "In  1  th episode,  48  th iteration, the average loss is:  221.578393364\n",
      "In  1  th episode,  49  th iteration, the average loss is:  1392.46053772\n",
      "In  1  th episode,  50  th iteration, the average loss is:  1962.28220369\n",
      "In  1  th episode,  51  th iteration, the average loss is:  534.285058457\n",
      "In  1  th episode,  52  th iteration, the average loss is:  314.96176856\n",
      "In  1  th episode,  53  th iteration, the average loss is:  305.916681862\n",
      "In  1  th episode,  54  th iteration, the average loss is:  142.544619501\n",
      "In  1  th episode,  55  th iteration, the average loss is:  741.920413385\n",
      "In  1  th episode,  56  th iteration, the average loss is:  286.002232003\n",
      "In  1  th episode,  57  th iteration, the average loss is:  337.339927119\n",
      "In  1  th episode,  58  th iteration, the average loss is:  236.745329571\n",
      "In  1  th episode,  59  th iteration, the average loss is:  3503.71521978\n",
      "In  1  th episode,  60  th iteration, the average loss is:  3237.6990695\n",
      "In  1  th episode,  61  th iteration, the average loss is:  800.281768751\n",
      "In  1  th episode,  62  th iteration, the average loss is:  260.694601536\n",
      "In  1  th episode,  63  th iteration, the average loss is:  137.757890308\n",
      "In  1  th episode,  64  th iteration, the average loss is:  315.930241066\n",
      "In  1  th episode,  65  th iteration, the average loss is:  3210.60422201\n",
      "In  1  th episode,  66  th iteration, the average loss is:  2337.9266304\n",
      "In  1  th episode,  67  th iteration, the average loss is:  2780.75075741\n",
      "In  1  th episode,  68  th iteration, the average loss is:  848.391455078\n",
      "In  1  th episode,  69  th iteration, the average loss is:  475.244260406\n",
      "In  1  th episode,  70  th iteration, the average loss is:  504.600470981\n",
      "In  1  th episode,  71  th iteration, the average loss is:  192.010820961\n",
      "In  1  th episode,  72  th iteration, the average loss is:  2431.68711439\n",
      "In  1  th episode,  73  th iteration, the average loss is:  1641.72223644\n",
      "In  1  th episode,  74  th iteration, the average loss is:  788.906972122\n",
      "In  1  th episode,  75  th iteration, the average loss is:  883.920722198\n",
      "In  1  th episode,  76  th iteration, the average loss is:  2896.33884735\n",
      "In  1  th episode,  77  th iteration, the average loss is:  2414.36924028\n",
      "In  1  th episode,  78  th iteration, the average loss is:  687.068263149\n",
      "In  1  th episode,  79  th iteration, the average loss is:  165.809304588\n",
      "In  1  th episode,  80  th iteration, the average loss is:  739.015976906\n",
      "In  1  th episode,  81  th iteration, the average loss is:  368.254760981\n",
      "In  1  th episode,  82  th iteration, the average loss is:  130.273488045\n",
      "In  1  th episode,  83  th iteration, the average loss is:  328.458678794\n",
      "In  1  th episode,  84  th iteration, the average loss is:  64.8374339461\n",
      "In  1  th episode,  85  th iteration, the average loss is:  285.216848398\n",
      "In  1  th episode,  86  th iteration, the average loss is:  618.472369814\n",
      "In  1  th episode,  87  th iteration, the average loss is:  130.294813234\n",
      "In  1  th episode,  88  th iteration, the average loss is:  2418.62577526\n",
      "In  1  th episode,  89  th iteration, the average loss is:  81.428085167\n",
      "In  1  th episode,  90  th iteration, the average loss is:  181.818088293\n",
      "In  1  th episode,  91  th iteration, the average loss is:  387.145659614\n",
      "In  1  th episode,  92  th iteration, the average loss is:  8515.47183027\n",
      "In  1  th episode,  93  th iteration, the average loss is:  1430.60755773\n",
      "In  1  th episode,  94  th iteration, the average loss is:  639.700332427\n",
      "In  1  th episode,  95  th iteration, the average loss is:  320.661217948\n",
      "In  1  th episode,  96  th iteration, the average loss is:  75763.9116865\n",
      "In  1  th episode,  97  th iteration, the average loss is:  432.162709713\n",
      "In  1  th episode,  98  th iteration, the average loss is:  690.789313718\n",
      "In  1  th episode,  99  th iteration, the average loss is:  8516.4626833\n",
      "In  1  th episode,  100  th iteration, the average loss is:  252.04228505\n",
      "In  2  th episode,  1  th iteration, the average loss is:  75347.5812928\n",
      "In  2  th episode,  2  th iteration, the average loss is:  10899.0100802\n",
      "In  2  th episode,  3  th iteration, the average loss is:  1562.48967674\n",
      "In  2  th episode,  4  th iteration, the average loss is:  18320.7998702\n",
      "In  2  th episode,  5  th iteration, the average loss is:  225.324631363\n",
      "In  2  th episode,  6  th iteration, the average loss is:  2632.52064931\n",
      "In  2  th episode,  7  th iteration, the average loss is:  1751.63435998\n",
      "In  2  th episode,  8  th iteration, the average loss is:  420.55882802\n",
      "In  2  th episode,  9  th iteration, the average loss is:  7602.29700642\n",
      "In  2  th episode,  10  th iteration, the average loss is:  892.33557663\n",
      "In  2  th episode,  11  th iteration, the average loss is:  2952.12556362\n",
      "In  2  th episode,  12  th iteration, the average loss is:  1456.89046968\n",
      "In  2  th episode,  13  th iteration, the average loss is:  335.811967659\n",
      "In  2  th episode,  14  th iteration, the average loss is:  864.856658602\n",
      "In  2  th episode,  15  th iteration, the average loss is:  227.040611506\n",
      "In  2  th episode,  16  th iteration, the average loss is:  2582.71183167\n",
      "In  2  th episode,  17  th iteration, the average loss is:  6365.0806883\n",
      "In  2  th episode,  18  th iteration, the average loss is:  453.901612282\n",
      "In  2  th episode,  19  th iteration, the average loss is:  6062.82686697\n",
      "In  2  th episode,  20  th iteration, the average loss is:  7544.53948095\n",
      "In  2  th episode,  21  th iteration, the average loss is:  2206.73285321\n",
      "In  2  th episode,  22  th iteration, the average loss is:  1654.4032733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  2  th episode,  23  th iteration, the average loss is:  91372.2673397\n",
      "In  2  th episode,  24  th iteration, the average loss is:  1644.03970622\n",
      "In  2  th episode,  25  th iteration, the average loss is:  873.987570542\n",
      "In  2  th episode,  26  th iteration, the average loss is:  203.707767439\n",
      "In  2  th episode,  27  th iteration, the average loss is:  283103.601387\n",
      "In  2  th episode,  28  th iteration, the average loss is:  6678.64238735\n",
      "In  2  th episode,  29  th iteration, the average loss is:  302.57541281\n",
      "In  2  th episode,  30  th iteration, the average loss is:  312.728109026\n",
      "In  2  th episode,  31  th iteration, the average loss is:  1170.98408737\n",
      "In  2  th episode,  32  th iteration, the average loss is:  6589.923386\n",
      "In  2  th episode,  33  th iteration, the average loss is:  2986.13728117\n",
      "In  2  th episode,  34  th iteration, the average loss is:  356.403582191\n",
      "In  2  th episode,  35  th iteration, the average loss is:  235.79991436\n",
      "In  2  th episode,  36  th iteration, the average loss is:  6827.10831001\n",
      "In  2  th episode,  37  th iteration, the average loss is:  178922.634871\n",
      "In  2  th episode,  38  th iteration, the average loss is:  210.022309929\n",
      "In  2  th episode,  39  th iteration, the average loss is:  1886.93142883\n",
      "In  2  th episode,  40  th iteration, the average loss is:  97.6262156963\n",
      "In  2  th episode,  41  th iteration, the average loss is:  8765.28131068\n",
      "In  2  th episode,  42  th iteration, the average loss is:  414.706920836\n",
      "In  2  th episode,  43  th iteration, the average loss is:  144257.291782\n",
      "In  2  th episode,  44  th iteration, the average loss is:  3374.66773909\n",
      "In  2  th episode,  45  th iteration, the average loss is:  284213.503364\n",
      "In  2  th episode,  46  th iteration, the average loss is:  18251.147203\n",
      "In  2  th episode,  47  th iteration, the average loss is:  91340.4622269\n",
      "In  2  th episode,  48  th iteration, the average loss is:  8993.88373787\n",
      "In  2  th episode,  49  th iteration, the average loss is:  4825.12758307\n",
      "In  2  th episode,  50  th iteration, the average loss is:  573539.309423\n",
      "In  2  th episode,  51  th iteration, the average loss is:  74324.2275791\n",
      "In  2  th episode,  52  th iteration, the average loss is:  300039.127002\n",
      "In  2  th episode,  53  th iteration, the average loss is:  91177.3171236\n",
      "In  2  th episode,  54  th iteration, the average loss is:  955.124954665\n",
      "In  2  th episode,  55  th iteration, the average loss is:  316660.074805\n",
      "In  2  th episode,  56  th iteration, the average loss is:  5929.69254532\n",
      "In  2  th episode,  57  th iteration, the average loss is:  565339.374697\n",
      "In  2  th episode,  58  th iteration, the average loss is:  368335.020456\n",
      "In  2  th episode,  59  th iteration, the average loss is:  81872.9313213\n",
      "In  2  th episode,  60  th iteration, the average loss is:  296605.436735\n",
      "In  2  th episode,  61  th iteration, the average loss is:  2691.40947666\n",
      "In  2  th episode,  62  th iteration, the average loss is:  9658.61977692\n",
      "In  2  th episode,  63  th iteration, the average loss is:  92773.8689503\n",
      "In  2  th episode,  64  th iteration, the average loss is:  14317.1315247\n",
      "In  2  th episode,  65  th iteration, the average loss is:  74969.8994531\n",
      "In  2  th episode,  66  th iteration, the average loss is:  1324.90023358\n",
      "In  2  th episode,  67  th iteration, the average loss is:  670484.248261\n",
      "In  2  th episode,  68  th iteration, the average loss is:  160.869284138\n",
      "In  2  th episode,  69  th iteration, the average loss is:  338.903255582\n",
      "In  2  th episode,  70  th iteration, the average loss is:  360179.970326\n",
      "In  2  th episode,  71  th iteration, the average loss is:  272469.619416\n",
      "In  2  th episode,  72  th iteration, the average loss is:  271192.822882\n",
      "In  2  th episode,  73  th iteration, the average loss is:  503781.431928\n",
      "In  2  th episode,  74  th iteration, the average loss is:  331524.355335\n",
      "In  2  th episode,  75  th iteration, the average loss is:  58855.2550327\n",
      "In  2  th episode,  76  th iteration, the average loss is:  84155.5165257\n",
      "In  2  th episode,  77  th iteration, the average loss is:  15417.7769033\n",
      "In  2  th episode,  78  th iteration, the average loss is:  111264.267233\n",
      "In  2  th episode,  79  th iteration, the average loss is:  9702.45130535\n",
      "In  2  th episode,  80  th iteration, the average loss is:  173583.153982\n",
      "In  2  th episode,  81  th iteration, the average loss is:  7500.78926034\n",
      "In  2  th episode,  82  th iteration, the average loss is:  229742.229421\n",
      "In  2  th episode,  83  th iteration, the average loss is:  4759.58028121\n",
      "In  2  th episode,  84  th iteration, the average loss is:  430393.036004\n",
      "In  2  th episode,  85  th iteration, the average loss is:  427184.220233\n",
      "In  2  th episode,  86  th iteration, the average loss is:  8031.52793337\n",
      "In  2  th episode,  87  th iteration, the average loss is:  241891.050419\n",
      "In  2  th episode,  88  th iteration, the average loss is:  357005.176331\n",
      "In  2  th episode,  89  th iteration, the average loss is:  262163.793622\n",
      "In  2  th episode,  90  th iteration, the average loss is:  326317.089799\n",
      "In  2  th episode,  91  th iteration, the average loss is:  476737.02866\n",
      "In  2  th episode,  92  th iteration, the average loss is:  59443.0802756\n",
      "In  2  th episode,  93  th iteration, the average loss is:  31034.3207934\n",
      "In  2  th episode,  94  th iteration, the average loss is:  3977.89827328\n",
      "In  2  th episode,  95  th iteration, the average loss is:  398917.252018\n",
      "In  2  th episode,  96  th iteration, the average loss is:  399049.461205\n",
      "In  2  th episode,  97  th iteration, the average loss is:  358857.469894\n",
      "In  2  th episode,  98  th iteration, the average loss is:  286065.163077\n",
      "In  2  th episode,  99  th iteration, the average loss is:  313931.573418\n",
      "In  2  th episode,  100  th iteration, the average loss is:  3747.84699411\n",
      "In  3  th episode,  1  th iteration, the average loss is:  73713.6176319\n",
      "In  3  th episode,  2  th iteration, the average loss is:  359495.502556\n",
      "In  3  th episode,  3  th iteration, the average loss is:  431468.712736\n",
      "In  3  th episode,  4  th iteration, the average loss is:  267220.475912\n",
      "In  3  th episode,  5  th iteration, the average loss is:  91271.2372101\n",
      "In  3  th episode,  6  th iteration, the average loss is:  499810.225148\n",
      "In  3  th episode,  7  th iteration, the average loss is:  4231.12264733\n",
      "In  3  th episode,  8  th iteration, the average loss is:  97043.5520372\n",
      "In  3  th episode,  9  th iteration, the average loss is:  800069.816589\n",
      "In  3  th episode,  10  th iteration, the average loss is:  100785.833085\n",
      "In  3  th episode,  11  th iteration, the average loss is:  113237.148056\n",
      "In  3  th episode,  12  th iteration, the average loss is:  276248.723561\n",
      "In  3  th episode,  13  th iteration, the average loss is:  90872.0544378\n",
      "In  3  th episode,  14  th iteration, the average loss is:  79437.6217298\n",
      "In  3  th episode,  15  th iteration, the average loss is:  10508.1650162\n",
      "In  3  th episode,  16  th iteration, the average loss is:  146925.374827\n",
      "In  3  th episode,  17  th iteration, the average loss is:  291836.448359\n",
      "In  3  th episode,  18  th iteration, the average loss is:  19306.7187149\n",
      "In  3  th episode,  19  th iteration, the average loss is:  587529.556815\n",
      "In  3  th episode,  20  th iteration, the average loss is:  6207.99521796\n",
      "In  3  th episode,  21  th iteration, the average loss is:  243805.257006\n",
      "In  3  th episode,  22  th iteration, the average loss is:  437055.940116\n",
      "In  3  th episode,  23  th iteration, the average loss is:  230065.072545\n",
      "In  3  th episode,  24  th iteration, the average loss is:  336499.890597\n",
      "In  3  th episode,  25  th iteration, the average loss is:  118475.333372\n",
      "In  3  th episode,  26  th iteration, the average loss is:  343893.527818\n",
      "In  3  th episode,  27  th iteration, the average loss is:  241785.330789\n",
      "In  3  th episode,  28  th iteration, the average loss is:  338401.898868\n",
      "In  3  th episode,  29  th iteration, the average loss is:  100805.021214\n",
      "In  3  th episode,  30  th iteration, the average loss is:  614617.374643\n",
      "In  3  th episode,  31  th iteration, the average loss is:  233999.626144\n",
      "In  3  th episode,  32  th iteration, the average loss is:  321722.838672\n",
      "In  3  th episode,  33  th iteration, the average loss is:  7730.48923645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  3  th episode,  34  th iteration, the average loss is:  266816.777807\n",
      "In  3  th episode,  35  th iteration, the average loss is:  91329.1225777\n",
      "In  3  th episode,  36  th iteration, the average loss is:  48536.9224723\n",
      "In  3  th episode,  37  th iteration, the average loss is:  221174.537888\n",
      "In  3  th episode,  38  th iteration, the average loss is:  110412.173838\n",
      "In  3  th episode,  39  th iteration, the average loss is:  2460.94246559\n",
      "In  3  th episode,  40  th iteration, the average loss is:  651639.413\n",
      "In  3  th episode,  41  th iteration, the average loss is:  374068.407724\n",
      "In  3  th episode,  42  th iteration, the average loss is:  564694.543527\n",
      "In  3  th episode,  43  th iteration, the average loss is:  408553.010432\n",
      "In  3  th episode,  44  th iteration, the average loss is:  208392.21857\n",
      "In  3  th episode,  45  th iteration, the average loss is:  242965.437732\n",
      "In  3  th episode,  46  th iteration, the average loss is:  241467.102258\n",
      "In  3  th episode,  47  th iteration, the average loss is:  810312.426739\n",
      "In  3  th episode,  48  th iteration, the average loss is:  55087.4266846\n",
      "In  3  th episode,  49  th iteration, the average loss is:  114564.967756\n",
      "In  3  th episode,  50  th iteration, the average loss is:  377516.675672\n",
      "In  3  th episode,  51  th iteration, the average loss is:  252205.000737\n",
      "In  3  th episode,  52  th iteration, the average loss is:  455163.150681\n",
      "In  3  th episode,  53  th iteration, the average loss is:  528352.439803\n",
      "In  3  th episode,  54  th iteration, the average loss is:  123733.25257\n",
      "In  3  th episode,  55  th iteration, the average loss is:  94500.0048685\n",
      "In  3  th episode,  56  th iteration, the average loss is:  1932.75429177\n",
      "In  3  th episode,  57  th iteration, the average loss is:  277296.999178\n",
      "In  3  th episode,  58  th iteration, the average loss is:  103924.425954\n",
      "In  3  th episode,  59  th iteration, the average loss is:  844362.036488\n",
      "In  3  th episode,  60  th iteration, the average loss is:  417574.670497\n",
      "In  3  th episode,  61  th iteration, the average loss is:  224897.683441\n",
      "In  3  th episode,  62  th iteration, the average loss is:  682816.299383\n",
      "In  3  th episode,  63  th iteration, the average loss is:  208314.929315\n",
      "In  3  th episode,  64  th iteration, the average loss is:  261167.633222\n",
      "In  3  th episode,  65  th iteration, the average loss is:  319624.781485\n",
      "In  3  th episode,  66  th iteration, the average loss is:  60471.1843453\n",
      "In  3  th episode,  67  th iteration, the average loss is:  179608.049391\n",
      "In  3  th episode,  68  th iteration, the average loss is:  244407.680579\n",
      "In  3  th episode,  69  th iteration, the average loss is:  400741.513585\n",
      "In  3  th episode,  70  th iteration, the average loss is:  251358.751207\n",
      "In  3  th episode,  71  th iteration, the average loss is:  366694.91741\n",
      "In  3  th episode,  72  th iteration, the average loss is:  32995.7467804\n",
      "In  3  th episode,  73  th iteration, the average loss is:  196354.331853\n",
      "In  3  th episode,  74  th iteration, the average loss is:  245924.700541\n",
      "In  3  th episode,  75  th iteration, the average loss is:  223707.892347\n",
      "In  3  th episode,  76  th iteration, the average loss is:  211381.820811\n",
      "In  3  th episode,  77  th iteration, the average loss is:  110211.050994\n",
      "In  3  th episode,  78  th iteration, the average loss is:  503611.105527\n",
      "In  3  th episode,  79  th iteration, the average loss is:  645820.219931\n",
      "In  3  th episode,  80  th iteration, the average loss is:  347606.362092\n",
      "In  3  th episode,  81  th iteration, the average loss is:  362152.080238\n",
      "In  3  th episode,  82  th iteration, the average loss is:  654461.2013\n",
      "In  3  th episode,  83  th iteration, the average loss is:  154888.595007\n",
      "In  3  th episode,  84  th iteration, the average loss is:  212295.194376\n",
      "In  3  th episode,  85  th iteration, the average loss is:  854655.637184\n",
      "In  3  th episode,  86  th iteration, the average loss is:  122569.999701\n",
      "In  3  th episode,  87  th iteration, the average loss is:  552045.468218\n",
      "In  3  th episode,  88  th iteration, the average loss is:  330394.23278\n",
      "In  3  th episode,  89  th iteration, the average loss is:  575276.414481\n",
      "In  3  th episode,  90  th iteration, the average loss is:  639506.375583\n",
      "In  3  th episode,  91  th iteration, the average loss is:  457245.396738\n",
      "In  3  th episode,  92  th iteration, the average loss is:  494101.023338\n",
      "In  3  th episode,  93  th iteration, the average loss is:  181169.674767\n",
      "In  3  th episode,  94  th iteration, the average loss is:  664590.493983\n",
      "In  3  th episode,  95  th iteration, the average loss is:  271372.99408\n",
      "In  3  th episode,  96  th iteration, the average loss is:  133063.420944\n",
      "In  3  th episode,  97  th iteration, the average loss is:  176968.360353\n",
      "In  3  th episode,  98  th iteration, the average loss is:  275925.196307\n",
      "In  3  th episode,  99  th iteration, the average loss is:  424002.9821\n",
      "In  3  th episode,  100  th iteration, the average loss is:  854176.845665\n",
      "In  4  th episode,  1  th iteration, the average loss is:  831255.012029\n",
      "In  4  th episode,  2  th iteration, the average loss is:  187582.377857\n",
      "In  4  th episode,  3  th iteration, the average loss is:  336053.575176\n",
      "In  4  th episode,  4  th iteration, the average loss is:  159228.051003\n",
      "In  4  th episode,  5  th iteration, the average loss is:  16602.943146\n",
      "In  4  th episode,  6  th iteration, the average loss is:  169770.422049\n",
      "In  4  th episode,  7  th iteration, the average loss is:  238228.251918\n",
      "In  4  th episode,  8  th iteration, the average loss is:  624379.570704\n",
      "In  4  th episode,  9  th iteration, the average loss is:  510505.031766\n",
      "In  4  th episode,  10  th iteration, the average loss is:  104630.189951\n",
      "In  4  th episode,  11  th iteration, the average loss is:  723640.325162\n",
      "In  4  th episode,  12  th iteration, the average loss is:  350583.112949\n",
      "In  4  th episode,  13  th iteration, the average loss is:  342197.412008\n",
      "In  4  th episode,  14  th iteration, the average loss is:  25057.621701\n",
      "In  4  th episode,  15  th iteration, the average loss is:  631586.786661\n",
      "In  4  th episode,  16  th iteration, the average loss is:  258179.919749\n",
      "In  4  th episode,  17  th iteration, the average loss is:  504820.61804\n",
      "In  4  th episode,  18  th iteration, the average loss is:  141278.057184\n",
      "In  4  th episode,  19  th iteration, the average loss is:  254038.256732\n",
      "In  4  th episode,  20  th iteration, the average loss is:  296910.223098\n",
      "In  4  th episode,  21  th iteration, the average loss is:  302802.903292\n",
      "In  4  th episode,  22  th iteration, the average loss is:  379988.804526\n",
      "In  4  th episode,  23  th iteration, the average loss is:  90615.944438\n",
      "In  4  th episode,  24  th iteration, the average loss is:  574791.439906\n",
      "In  4  th episode,  25  th iteration, the average loss is:  557198.147964\n",
      "In  4  th episode,  26  th iteration, the average loss is:  279500.091324\n",
      "In  4  th episode,  27  th iteration, the average loss is:  649994.508867\n",
      "In  4  th episode,  28  th iteration, the average loss is:  650619.33985\n",
      "In  4  th episode,  29  th iteration, the average loss is:  429516.098622\n",
      "In  4  th episode,  30  th iteration, the average loss is:  180499.814169\n",
      "In  4  th episode,  31  th iteration, the average loss is:  252933.40257\n",
      "In  4  th episode,  32  th iteration, the average loss is:  202108.15537\n",
      "In  4  th episode,  33  th iteration, the average loss is:  831034.007009\n",
      "In  4  th episode,  34  th iteration, the average loss is:  715784.297238\n",
      "In  4  th episode,  35  th iteration, the average loss is:  245812.382334\n",
      "In  4  th episode,  36  th iteration, the average loss is:  289156.230533\n",
      "In  4  th episode,  37  th iteration, the average loss is:  295655.33006\n",
      "In  4  th episode,  38  th iteration, the average loss is:  823040.453299\n",
      "In  4  th episode,  39  th iteration, the average loss is:  203945.61357\n",
      "In  4  th episode,  40  th iteration, the average loss is:  501023.979276\n",
      "In  4  th episode,  41  th iteration, the average loss is:  554252.144731\n",
      "In  4  th episode,  42  th iteration, the average loss is:  523088.719226\n",
      "In  4  th episode,  43  th iteration, the average loss is:  284111.292786\n",
      "In  4  th episode,  44  th iteration, the average loss is:  558095.896297\n",
      "In  4  th episode,  45  th iteration, the average loss is:  483981.577658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  4  th episode,  46  th iteration, the average loss is:  551641.201027\n",
      "In  4  th episode,  47  th iteration, the average loss is:  180784.832559\n",
      "In  4  th episode,  48  th iteration, the average loss is:  123397.724124\n",
      "In  4  th episode,  49  th iteration, the average loss is:  190855.950792\n",
      "In  4  th episode,  50  th iteration, the average loss is:  528993.87168\n",
      "In  4  th episode,  51  th iteration, the average loss is:  164503.631586\n",
      "In  4  th episode,  52  th iteration, the average loss is:  444647.119854\n",
      "In  4  th episode,  53  th iteration, the average loss is:  165528.741566\n",
      "In  4  th episode,  54  th iteration, the average loss is:  770025.616528\n",
      "In  4  th episode,  55  th iteration, the average loss is:  207922.130357\n",
      "In  4  th episode,  56  th iteration, the average loss is:  120482.734051\n",
      "In  4  th episode,  57  th iteration, the average loss is:  362850.786304\n",
      "In  4  th episode,  58  th iteration, the average loss is:  192680.243896\n",
      "In  4  th episode,  59  th iteration, the average loss is:  100333.01886\n",
      "In  4  th episode,  60  th iteration, the average loss is:  309994.184444\n",
      "In  4  th episode,  61  th iteration, the average loss is:  221050.681706\n",
      "In  4  th episode,  62  th iteration, the average loss is:  666884.510467\n",
      "In  4  th episode,  63  th iteration, the average loss is:  309777.715867\n",
      "In  4  th episode,  64  th iteration, the average loss is:  441501.751692\n",
      "In  4  th episode,  65  th iteration, the average loss is:  499164.549536\n",
      "In  4  th episode,  66  th iteration, the average loss is:  675508.951001\n",
      "In  4  th episode,  67  th iteration, the average loss is:  391695.349166\n",
      "In  4  th episode,  68  th iteration, the average loss is:  96401.9687591\n",
      "In  4  th episode,  69  th iteration, the average loss is:  392388.633041\n",
      "In  4  th episode,  70  th iteration, the average loss is:  313527.341041\n",
      "In  4  th episode,  71  th iteration, the average loss is:  319135.785737\n",
      "In  4  th episode,  72  th iteration, the average loss is:  35385.0836237\n",
      "In  4  th episode,  73  th iteration, the average loss is:  632146.76475\n",
      "In  4  th episode,  74  th iteration, the average loss is:  259800.640364\n",
      "In  4  th episode,  75  th iteration, the average loss is:  208569.617157\n",
      "In  4  th episode,  76  th iteration, the average loss is:  207540.656537\n",
      "In  4  th episode,  77  th iteration, the average loss is:  624121.978828\n",
      "In  4  th episode,  78  th iteration, the average loss is:  503998.485201\n",
      "In  4  th episode,  79  th iteration, the average loss is:  607475.513196\n",
      "In  4  th episode,  80  th iteration, the average loss is:  433666.662691\n",
      "In  4  th episode,  81  th iteration, the average loss is:  359902.218955\n",
      "In  4  th episode,  82  th iteration, the average loss is:  853713.098578\n",
      "In  4  th episode,  83  th iteration, the average loss is:  139048.108375\n",
      "In  4  th episode,  84  th iteration, the average loss is:  327764.751575\n",
      "In  4  th episode,  85  th iteration, the average loss is:  566919.877208\n",
      "In  4  th episode,  86  th iteration, the average loss is:  408309.600565\n",
      "In  4  th episode,  87  th iteration, the average loss is:  440321.473777\n",
      "In  4  th episode,  88  th iteration, the average loss is:  666468.964908\n",
      "In  4  th episode,  89  th iteration, the average loss is:  362955.39957\n",
      "In  4  th episode,  90  th iteration, the average loss is:  607267.356211\n",
      "In  4  th episode,  91  th iteration, the average loss is:  157833.131522\n",
      "In  4  th episode,  92  th iteration, the average loss is:  518335.673035\n",
      "In  4  th episode,  93  th iteration, the average loss is:  766559.572205\n",
      "In  4  th episode,  94  th iteration, the average loss is:  805626.004388\n",
      "In  4  th episode,  95  th iteration, the average loss is:  23498.7497713\n",
      "In  4  th episode,  96  th iteration, the average loss is:  322950.800391\n",
      "In  4  th episode,  97  th iteration, the average loss is:  930440.138234\n",
      "In  4  th episode,  98  th iteration, the average loss is:  416724.503876\n",
      "In  4  th episode,  99  th iteration, the average loss is:  563570.583284\n",
      "In  4  th episode,  100  th iteration, the average loss is:  684104.328836\n",
      "In  5  th episode,  1  th iteration, the average loss is:  295050.337169\n",
      "In  5  th episode,  2  th iteration, the average loss is:  383575.816127\n",
      "In  5  th episode,  3  th iteration, the average loss is:  1016251.50051\n",
      "In  5  th episode,  4  th iteration, the average loss is:  388893.122619\n",
      "In  5  th episode,  5  th iteration, the average loss is:  186488.115533\n",
      "In  5  th episode,  6  th iteration, the average loss is:  239004.390421\n",
      "In  5  th episode,  7  th iteration, the average loss is:  110585.600166\n",
      "In  5  th episode,  8  th iteration, the average loss is:  258111.985898\n",
      "In  5  th episode,  9  th iteration, the average loss is:  560461.883154\n",
      "In  5  th episode,  10  th iteration, the average loss is:  93261.2714081\n",
      "In  5  th episode,  11  th iteration, the average loss is:  430311.541846\n",
      "In  5  th episode,  12  th iteration, the average loss is:  69581.3565796\n",
      "In  5  th episode,  13  th iteration, the average loss is:  323873.91723\n",
      "In  5  th episode,  14  th iteration, the average loss is:  441024.41792\n",
      "In  5  th episode,  15  th iteration, the average loss is:  243985.210428\n",
      "In  5  th episode,  16  th iteration, the average loss is:  286742.08449\n",
      "In  5  th episode,  17  th iteration, the average loss is:  792695.449081\n",
      "In  5  th episode,  18  th iteration, the average loss is:  330527.764752\n",
      "In  5  th episode,  19  th iteration, the average loss is:  577509.091083\n",
      "In  5  th episode,  20  th iteration, the average loss is:  329168.554791\n",
      "In  5  th episode,  21  th iteration, the average loss is:  259472.881566\n",
      "In  5  th episode,  22  th iteration, the average loss is:  324216.695343\n",
      "In  5  th episode,  23  th iteration, the average loss is:  299774.204732\n",
      "In  5  th episode,  24  th iteration, the average loss is:  449546.832288\n",
      "In  5  th episode,  25  th iteration, the average loss is:  299133.809119\n",
      "In  5  th episode,  26  th iteration, the average loss is:  407403.140314\n",
      "In  5  th episode,  27  th iteration, the average loss is:  84321.7392262\n",
      "In  5  th episode,  28  th iteration, the average loss is:  289373.835042\n",
      "In  5  th episode,  29  th iteration, the average loss is:  72456.6392433\n",
      "In  5  th episode,  30  th iteration, the average loss is:  492268.030322\n",
      "In  5  th episode,  31  th iteration, the average loss is:  482631.059693\n",
      "In  5  th episode,  32  th iteration, the average loss is:  643337.665607\n",
      "In  5  th episode,  33  th iteration, the average loss is:  620694.121033\n",
      "In  5  th episode,  34  th iteration, the average loss is:  178506.672861\n",
      "In  5  th episode,  35  th iteration, the average loss is:  673417.281661\n",
      "In  5  th episode,  36  th iteration, the average loss is:  265879.415648\n",
      "In  5  th episode,  37  th iteration, the average loss is:  224014.122955\n",
      "In  5  th episode,  38  th iteration, the average loss is:  325196.48628\n",
      "In  5  th episode,  39  th iteration, the average loss is:  225041.800484\n",
      "In  5  th episode,  40  th iteration, the average loss is:  307617.614697\n",
      "In  5  th episode,  41  th iteration, the average loss is:  248611.70523\n",
      "In  5  th episode,  42  th iteration, the average loss is:  530371.890869\n",
      "In  5  th episode,  43  th iteration, the average loss is:  208549.824707\n",
      "In  5  th episode,  44  th iteration, the average loss is:  239832.869537\n",
      "In  5  th episode,  45  th iteration, the average loss is:  684389.146582\n",
      "In  5  th episode,  46  th iteration, the average loss is:  401798.238593\n",
      "In  5  th episode,  47  th iteration, the average loss is:  229895.882484\n",
      "In  5  th episode,  48  th iteration, the average loss is:  137487.232313\n",
      "In  5  th episode,  49  th iteration, the average loss is:  252521.617407\n",
      "In  5  th episode,  50  th iteration, the average loss is:  375409.469391\n",
      "In  5  th episode,  51  th iteration, the average loss is:  111134.485846\n",
      "In  5  th episode,  52  th iteration, the average loss is:  314569.361163\n",
      "In  5  th episode,  53  th iteration, the average loss is:  136794.958679\n",
      "In  5  th episode,  54  th iteration, the average loss is:  452983.421198\n",
      "In  5  th episode,  55  th iteration, the average loss is:  570886.87478\n",
      "In  5  th episode,  56  th iteration, the average loss is:  414221.564856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  5  th episode,  57  th iteration, the average loss is:  308931.766187\n",
      "In  5  th episode,  58  th iteration, the average loss is:  392173.278566\n",
      "In  5  th episode,  59  th iteration, the average loss is:  288550.013548\n",
      "In  5  th episode,  60  th iteration, the average loss is:  341009.6396\n",
      "In  5  th episode,  61  th iteration, the average loss is:  318394.52787\n",
      "In  5  th episode,  62  th iteration, the average loss is:  213238.341788\n",
      "In  5  th episode,  63  th iteration, the average loss is:  309302.895601\n",
      "In  5  th episode,  64  th iteration, the average loss is:  218325.282524\n",
      "In  5  th episode,  65  th iteration, the average loss is:  233453.062109\n",
      "In  5  th episode,  66  th iteration, the average loss is:  221061.780727\n",
      "In  5  th episode,  67  th iteration, the average loss is:  385567.052681\n",
      "In  5  th episode,  68  th iteration, the average loss is:  292988.101773\n",
      "In  5  th episode,  69  th iteration, the average loss is:  137809.344446\n",
      "In  5  th episode,  70  th iteration, the average loss is:  391585.35353\n",
      "In  5  th episode,  71  th iteration, the average loss is:  244155.218042\n",
      "In  5  th episode,  72  th iteration, the average loss is:  283146.168994\n",
      "In  5  th episode,  73  th iteration, the average loss is:  163790.182306\n",
      "In  5  th episode,  74  th iteration, the average loss is:  363288.546719\n",
      "In  5  th episode,  75  th iteration, the average loss is:  95043.2549881\n",
      "In  5  th episode,  76  th iteration, the average loss is:  519552.889116\n",
      "In  5  th episode,  77  th iteration, the average loss is:  39246.7296772\n",
      "In  5  th episode,  78  th iteration, the average loss is:  190091.062589\n",
      "In  5  th episode,  79  th iteration, the average loss is:  120658.166251\n",
      "In  5  th episode,  80  th iteration, the average loss is:  232114.402765\n",
      "In  5  th episode,  81  th iteration, the average loss is:  220410.318799\n",
      "In  5  th episode,  82  th iteration, the average loss is:  106868.682129\n",
      "In  5  th episode,  83  th iteration, the average loss is:  261935.623895\n",
      "In  5  th episode,  84  th iteration, the average loss is:  423089.638146\n",
      "In  5  th episode,  85  th iteration, the average loss is:  63791.4579224\n",
      "In  5  th episode,  86  th iteration, the average loss is:  35263.1499756\n",
      "In  5  th episode,  87  th iteration, the average loss is:  465560.969678\n",
      "In  5  th episode,  88  th iteration, the average loss is:  159015.387854\n",
      "In  5  th episode,  89  th iteration, the average loss is:  217938.141816\n",
      "In  5  th episode,  90  th iteration, the average loss is:  135988.405699\n",
      "In  5  th episode,  91  th iteration, the average loss is:  116210.943211\n",
      "In  5  th episode,  92  th iteration, the average loss is:  174337.40518\n",
      "In  5  th episode,  93  th iteration, the average loss is:  115003.823395\n",
      "In  5  th episode,  94  th iteration, the average loss is:  276136.651074\n",
      "In  5  th episode,  95  th iteration, the average loss is:  128805.635913\n",
      "In  5  th episode,  96  th iteration, the average loss is:  233797.429017\n",
      "In  5  th episode,  97  th iteration, the average loss is:  226605.622559\n",
      "In  5  th episode,  98  th iteration, the average loss is:  17159.7367317\n",
      "In  5  th episode,  99  th iteration, the average loss is:  353882.05607\n",
      "In  5  th episode,  100  th iteration, the average loss is:  17956.1314743\n",
      "In  6  th episode,  1  th iteration, the average loss is:  205742.780897\n",
      "In  6  th episode,  2  th iteration, the average loss is:  372957.370898\n",
      "In  6  th episode,  3  th iteration, the average loss is:  204102.517555\n",
      "In  6  th episode,  4  th iteration, the average loss is:  310742.070472\n",
      "In  6  th episode,  5  th iteration, the average loss is:  188086.666177\n",
      "In  6  th episode,  6  th iteration, the average loss is:  205670.858552\n",
      "In  6  th episode,  7  th iteration, the average loss is:  163727.039826\n",
      "In  6  th episode,  8  th iteration, the average loss is:  325505.162596\n",
      "In  6  th episode,  9  th iteration, the average loss is:  180544.126233\n",
      "In  6  th episode,  10  th iteration, the average loss is:  214675.723077\n",
      "In  6  th episode,  11  th iteration, the average loss is:  272316.963081\n",
      "In  6  th episode,  12  th iteration, the average loss is:  86582.7288658\n",
      "In  6  th episode,  13  th iteration, the average loss is:  181296.447626\n",
      "In  6  th episode,  14  th iteration, the average loss is:  5674.92108574\n",
      "In  6  th episode,  15  th iteration, the average loss is:  194627.859671\n",
      "In  6  th episode,  16  th iteration, the average loss is:  212607.083203\n",
      "In  6  th episode,  17  th iteration, the average loss is:  110250.759541\n",
      "In  6  th episode,  18  th iteration, the average loss is:  378174.041787\n",
      "In  6  th episode,  19  th iteration, the average loss is:  85386.398164\n",
      "In  6  th episode,  20  th iteration, the average loss is:  235865.623945\n",
      "In  6  th episode,  21  th iteration, the average loss is:  143073.186685\n",
      "In  6  th episode,  22  th iteration, the average loss is:  145070.495139\n",
      "In  6  th episode,  23  th iteration, the average loss is:  244633.017643\n",
      "In  6  th episode,  24  th iteration, the average loss is:  152719.932101\n",
      "In  6  th episode,  25  th iteration, the average loss is:  188060.422979\n",
      "In  6  th episode,  26  th iteration, the average loss is:  196847.694344\n",
      "In  6  th episode,  27  th iteration, the average loss is:  136470.669618\n",
      "In  6  th episode,  28  th iteration, the average loss is:  247965.748099\n",
      "In  6  th episode,  29  th iteration, the average loss is:  141758.587662\n",
      "In  6  th episode,  30  th iteration, the average loss is:  158419.905265\n",
      "In  6  th episode,  31  th iteration, the average loss is:  443431.775363\n",
      "In  6  th episode,  32  th iteration, the average loss is:  432004.281348\n",
      "In  6  th episode,  33  th iteration, the average loss is:  216912.414668\n",
      "In  6  th episode,  34  th iteration, the average loss is:  121882.116453\n",
      "In  6  th episode,  35  th iteration, the average loss is:  215590.075958\n",
      "In  6  th episode,  36  th iteration, the average loss is:  330617.117896\n",
      "In  6  th episode,  37  th iteration, the average loss is:  146919.744208\n",
      "In  6  th episode,  38  th iteration, the average loss is:  84495.4393921\n",
      "In  6  th episode,  39  th iteration, the average loss is:  184614.533496\n",
      "In  6  th episode,  40  th iteration, the average loss is:  229945.699854\n",
      "In  6  th episode,  41  th iteration, the average loss is:  116499.108752\n",
      "In  6  th episode,  42  th iteration, the average loss is:  160348.714527\n",
      "In  6  th episode,  43  th iteration, the average loss is:  110903.237921\n",
      "In  6  th episode,  44  th iteration, the average loss is:  91223.3846105\n",
      "In  6  th episode,  45  th iteration, the average loss is:  92095.3912964\n",
      "In  6  th episode,  46  th iteration, the average loss is:  109293.903491\n",
      "In  6  th episode,  47  th iteration, the average loss is:  86018.3876251\n",
      "In  6  th episode,  48  th iteration, the average loss is:  180332.315237\n",
      "In  6  th episode,  49  th iteration, the average loss is:  185183.760251\n",
      "In  6  th episode,  50  th iteration, the average loss is:  117187.491188\n",
      "In  6  th episode,  51  th iteration, the average loss is:  177181.862032\n",
      "In  6  th episode,  52  th iteration, the average loss is:  60172.2503696\n",
      "In  6  th episode,  53  th iteration, the average loss is:  141918.400482\n",
      "In  6  th episode,  54  th iteration, the average loss is:  232448.464616\n",
      "In  6  th episode,  55  th iteration, the average loss is:  602336.763586\n",
      "In  6  th episode,  56  th iteration, the average loss is:  115994.831963\n",
      "In  6  th episode,  57  th iteration, the average loss is:  168394.292383\n",
      "In  6  th episode,  58  th iteration, the average loss is:  258956.389423\n",
      "In  6  th episode,  59  th iteration, the average loss is:  175531.629401\n",
      "In  6  th episode,  60  th iteration, the average loss is:  335225.513257\n",
      "In  6  th episode,  61  th iteration, the average loss is:  397137.683448\n",
      "In  6  th episode,  62  th iteration, the average loss is:  107707.491563\n",
      "In  6  th episode,  63  th iteration, the average loss is:  173932.491507\n",
      "In  6  th episode,  64  th iteration, the average loss is:  193145.55309\n",
      "In  6  th episode,  65  th iteration, the average loss is:  82006.7036743\n",
      "In  6  th episode,  66  th iteration, the average loss is:  93305.3653381\n",
      "In  6  th episode,  67  th iteration, the average loss is:  109856.969263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  6  th episode,  68  th iteration, the average loss is:  97282.9139525\n",
      "In  6  th episode,  69  th iteration, the average loss is:  160518.313225\n",
      "In  6  th episode,  70  th iteration, the average loss is:  127518.383887\n",
      "In  6  th episode,  71  th iteration, the average loss is:  155962.217542\n",
      "In  6  th episode,  72  th iteration, the average loss is:  130421.61678\n",
      "In  6  th episode,  73  th iteration, the average loss is:  58827.4837231\n",
      "In  6  th episode,  74  th iteration, the average loss is:  134708.215133\n",
      "In  6  th episode,  75  th iteration, the average loss is:  127858.693595\n",
      "In  6  th episode,  76  th iteration, the average loss is:  60206.9488396\n",
      "In  6  th episode,  77  th iteration, the average loss is:  84735.9233124\n",
      "In  6  th episode,  78  th iteration, the average loss is:  288315.336273\n",
      "In  6  th episode,  79  th iteration, the average loss is:  62840.1485996\n",
      "In  6  th episode,  80  th iteration, the average loss is:  54939.7187454\n",
      "In  6  th episode,  81  th iteration, the average loss is:  112785.8765\n",
      "In  6  th episode,  82  th iteration, the average loss is:  201822.691443\n",
      "In  6  th episode,  83  th iteration, the average loss is:  134599.981976\n",
      "In  6  th episode,  84  th iteration, the average loss is:  108406.778327\n",
      "In  6  th episode,  85  th iteration, the average loss is:  93161.6803366\n",
      "In  6  th episode,  86  th iteration, the average loss is:  72690.9104998\n",
      "In  6  th episode,  87  th iteration, the average loss is:  117803.914213\n",
      "In  6  th episode,  88  th iteration, the average loss is:  143254.505994\n",
      "In  6  th episode,  89  th iteration, the average loss is:  107022.102847\n",
      "In  6  th episode,  90  th iteration, the average loss is:  25780.6858894\n",
      "In  6  th episode,  91  th iteration, the average loss is:  135939.986758\n",
      "In  6  th episode,  92  th iteration, the average loss is:  397081.862848\n",
      "In  6  th episode,  93  th iteration, the average loss is:  145452.742691\n",
      "In  6  th episode,  94  th iteration, the average loss is:  75204.6816956\n",
      "In  6  th episode,  95  th iteration, the average loss is:  109910.643461\n",
      "In  6  th episode,  96  th iteration, the average loss is:  82208.3170776\n",
      "In  6  th episode,  97  th iteration, the average loss is:  71642.2546326\n",
      "In  6  th episode,  98  th iteration, the average loss is:  87142.9428268\n",
      "In  6  th episode,  99  th iteration, the average loss is:  206458.409824\n",
      "In  6  th episode,  100  th iteration, the average loss is:  378142.959066\n",
      "In  7  th episode,  1  th iteration, the average loss is:  266987.392749\n",
      "In  7  th episode,  2  th iteration, the average loss is:  196228.498059\n",
      "In  7  th episode,  3  th iteration, the average loss is:  104255.372985\n",
      "In  7  th episode,  4  th iteration, the average loss is:  147747.981861\n",
      "In  7  th episode,  5  th iteration, the average loss is:  64753.2079475\n",
      "In  7  th episode,  6  th iteration, the average loss is:  122277.180182\n",
      "In  7  th episode,  7  th iteration, the average loss is:  173851.3263\n",
      "In  7  th episode,  8  th iteration, the average loss is:  128549.235208\n",
      "In  7  th episode,  9  th iteration, the average loss is:  182200.365517\n",
      "In  7  th episode,  10  th iteration, the average loss is:  95625.9800162\n",
      "In  7  th episode,  11  th iteration, the average loss is:  75102.4047195\n",
      "In  7  th episode,  12  th iteration, the average loss is:  182231.918682\n",
      "In  7  th episode,  13  th iteration, the average loss is:  151418.895178\n",
      "In  7  th episode,  14  th iteration, the average loss is:  275223.113314\n",
      "In  7  th episode,  15  th iteration, the average loss is:  158802.257376\n",
      "In  7  th episode,  16  th iteration, the average loss is:  43092.4828228\n",
      "In  7  th episode,  17  th iteration, the average loss is:  96762.9221436\n",
      "In  7  th episode,  18  th iteration, the average loss is:  157524.327448\n",
      "In  7  th episode,  19  th iteration, the average loss is:  226006.743011\n",
      "In  7  th episode,  20  th iteration, the average loss is:  234152.118169\n",
      "In  7  th episode,  21  th iteration, the average loss is:  100059.744657\n",
      "In  7  th episode,  22  th iteration, the average loss is:  158001.340582\n",
      "In  7  th episode,  23  th iteration, the average loss is:  133605.862577\n",
      "In  7  th episode,  24  th iteration, the average loss is:  104249.186716\n",
      "In  7  th episode,  25  th iteration, the average loss is:  38037.6525352\n",
      "In  7  th episode,  26  th iteration, the average loss is:  151210.348598\n",
      "In  7  th episode,  27  th iteration, the average loss is:  37878.2117634\n",
      "In  7  th episode,  28  th iteration, the average loss is:  187961.794482\n",
      "In  7  th episode,  29  th iteration, the average loss is:  16584.3626507\n",
      "In  7  th episode,  30  th iteration, the average loss is:  56748.0432765\n",
      "In  7  th episode,  31  th iteration, the average loss is:  126884.986469\n",
      "In  7  th episode,  32  th iteration, the average loss is:  64693.2570775\n",
      "In  7  th episode,  33  th iteration, the average loss is:  53500.9077332\n",
      "In  7  th episode,  34  th iteration, the average loss is:  84807.8412964\n",
      "In  7  th episode,  35  th iteration, the average loss is:  156203.525636\n",
      "In  7  th episode,  36  th iteration, the average loss is:  78730.0015228\n",
      "In  7  th episode,  37  th iteration, the average loss is:  39454.1851631\n",
      "In  7  th episode,  38  th iteration, the average loss is:  90618.0782171\n",
      "In  7  th episode,  39  th iteration, the average loss is:  311944.460165\n",
      "In  7  th episode,  40  th iteration, the average loss is:  95994.4438004\n",
      "In  7  th episode,  41  th iteration, the average loss is:  358566.396415\n",
      "In  7  th episode,  42  th iteration, the average loss is:  42148.228418\n",
      "In  7  th episode,  43  th iteration, the average loss is:  115721.659961\n",
      "In  7  th episode,  44  th iteration, the average loss is:  67187.7678061\n",
      "In  7  th episode,  45  th iteration, the average loss is:  108086.986014\n",
      "In  7  th episode,  46  th iteration, the average loss is:  40306.8119934\n",
      "In  7  th episode,  47  th iteration, the average loss is:  227035.543008\n",
      "In  7  th episode,  48  th iteration, the average loss is:  88348.7717572\n",
      "In  7  th episode,  49  th iteration, the average loss is:  266220.652245\n",
      "In  7  th episode,  50  th iteration, the average loss is:  8166.02129135\n",
      "In  7  th episode,  51  th iteration, the average loss is:  146674.278986\n",
      "In  7  th episode,  52  th iteration, the average loss is:  162759.334131\n",
      "In  7  th episode,  53  th iteration, the average loss is:  50151.9888672\n",
      "In  7  th episode,  54  th iteration, the average loss is:  48530.5654648\n",
      "In  7  th episode,  55  th iteration, the average loss is:  418723.173987\n",
      "In  7  th episode,  56  th iteration, the average loss is:  65336.9343567\n",
      "In  7  th episode,  57  th iteration, the average loss is:  143617.142334\n",
      "In  7  th episode,  58  th iteration, the average loss is:  57838.1165087\n",
      "In  7  th episode,  59  th iteration, the average loss is:  27408.0805637\n",
      "In  7  th episode,  60  th iteration, the average loss is:  47253.4933131\n",
      "In  7  th episode,  61  th iteration, the average loss is:  23014.9323486\n",
      "In  7  th episode,  62  th iteration, the average loss is:  140971.563438\n",
      "In  7  th episode,  63  th iteration, the average loss is:  116678.428308\n",
      "In  7  th episode,  64  th iteration, the average loss is:  18327.8854961\n",
      "In  7  th episode,  65  th iteration, the average loss is:  39570.4714783\n",
      "In  7  th episode,  66  th iteration, the average loss is:  265175.525732\n",
      "In  7  th episode,  67  th iteration, the average loss is:  295827.507846\n",
      "In  7  th episode,  68  th iteration, the average loss is:  52672.0832047\n",
      "In  7  th episode,  69  th iteration, the average loss is:  12095.9176117\n",
      "In  7  th episode,  70  th iteration, the average loss is:  115514.733429\n",
      "In  7  th episode,  71  th iteration, the average loss is:  112920.027915\n",
      "In  7  th episode,  72  th iteration, the average loss is:  39738.5254761\n",
      "In  7  th episode,  73  th iteration, the average loss is:  101949.225666\n",
      "In  7  th episode,  74  th iteration, the average loss is:  6968.00767193\n",
      "In  7  th episode,  75  th iteration, the average loss is:  58411.9131958\n",
      "In  7  th episode,  76  th iteration, the average loss is:  95781.4997456\n",
      "In  7  th episode,  77  th iteration, the average loss is:  71063.1380676\n",
      "In  7  th episode,  78  th iteration, the average loss is:  59964.7763214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  7  th episode,  79  th iteration, the average loss is:  70643.0950256\n",
      "In  7  th episode,  80  th iteration, the average loss is:  54383.9111427\n",
      "In  7  th episode,  81  th iteration, the average loss is:  169613.853181\n",
      "In  7  th episode,  82  th iteration, the average loss is:  108484.355935\n",
      "In  7  th episode,  83  th iteration, the average loss is:  59412.7074951\n",
      "In  7  th episode,  84  th iteration, the average loss is:  54644.1843384\n",
      "In  7  th episode,  85  th iteration, the average loss is:  22185.2496368\n",
      "In  7  th episode,  86  th iteration, the average loss is:  73843.5316589\n",
      "In  7  th episode,  87  th iteration, the average loss is:  11480.563884\n",
      "In  7  th episode,  88  th iteration, the average loss is:  26928.5835938\n",
      "In  7  th episode,  89  th iteration, the average loss is:  185649.195035\n",
      "In  7  th episode,  90  th iteration, the average loss is:  13364.8517269\n",
      "In  7  th episode,  91  th iteration, the average loss is:  39177.6517609\n",
      "In  7  th episode,  92  th iteration, the average loss is:  47363.1685638\n",
      "In  7  th episode,  93  th iteration, the average loss is:  79653.5303091\n",
      "In  7  th episode,  94  th iteration, the average loss is:  95830.9894476\n",
      "In  7  th episode,  95  th iteration, the average loss is:  17534.3214005\n",
      "In  7  th episode,  96  th iteration, the average loss is:  30772.8173058\n",
      "In  7  th episode,  97  th iteration, the average loss is:  39732.9897118\n",
      "In  7  th episode,  98  th iteration, the average loss is:  100930.712085\n",
      "In  7  th episode,  99  th iteration, the average loss is:  67708.1570694\n",
      "In  7  th episode,  100  th iteration, the average loss is:  126883.296252\n",
      "In  8  th episode,  1  th iteration, the average loss is:  24230.1696838\n",
      "In  8  th episode,  2  th iteration, the average loss is:  190907.829883\n",
      "In  8  th episode,  3  th iteration, the average loss is:  25366.1940598\n",
      "In  8  th episode,  4  th iteration, the average loss is:  131072.087243\n",
      "In  8  th episode,  5  th iteration, the average loss is:  125444.589441\n",
      "In  8  th episode,  6  th iteration, the average loss is:  29471.970665\n",
      "In  8  th episode,  7  th iteration, the average loss is:  23755.0778032\n",
      "In  8  th episode,  8  th iteration, the average loss is:  99500.607003\n",
      "In  8  th episode,  9  th iteration, the average loss is:  13434.195394\n",
      "In  8  th episode,  10  th iteration, the average loss is:  78796.9175403\n",
      "In  8  th episode,  11  th iteration, the average loss is:  18619.3322303\n",
      "In  8  th episode,  12  th iteration, the average loss is:  67645.9202553\n",
      "In  8  th episode,  13  th iteration, the average loss is:  65515.7205322\n",
      "In  8  th episode,  14  th iteration, the average loss is:  19407.3098877\n",
      "In  8  th episode,  15  th iteration, the average loss is:  81210.0649063\n",
      "In  8  th episode,  16  th iteration, the average loss is:  14509.8368626\n",
      "In  8  th episode,  17  th iteration, the average loss is:  21405.702581\n",
      "In  8  th episode,  18  th iteration, the average loss is:  19033.2105928\n",
      "In  8  th episode,  19  th iteration, the average loss is:  53560.7219364\n",
      "In  8  th episode,  20  th iteration, the average loss is:  5739.37178955\n",
      "In  8  th episode,  21  th iteration, the average loss is:  51767.3190796\n",
      "In  8  th episode,  22  th iteration, the average loss is:  33799.2848389\n",
      "In  8  th episode,  23  th iteration, the average loss is:  139525.335117\n",
      "In  8  th episode,  24  th iteration, the average loss is:  51993.0422653\n",
      "In  8  th episode,  25  th iteration, the average loss is:  3611.72957153\n",
      "In  8  th episode,  26  th iteration, the average loss is:  12382.5747281\n",
      "In  8  th episode,  27  th iteration, the average loss is:  77570.9718985\n",
      "In  8  th episode,  28  th iteration, the average loss is:  22489.546003\n",
      "In  8  th episode,  29  th iteration, the average loss is:  360170.959992\n",
      "In  8  th episode,  30  th iteration, the average loss is:  39862.4850159\n",
      "In  8  th episode,  31  th iteration, the average loss is:  17938.1388984\n",
      "In  8  th episode,  32  th iteration, the average loss is:  19242.2523926\n",
      "In  8  th episode,  33  th iteration, the average loss is:  22608.0486046\n",
      "In  8  th episode,  34  th iteration, the average loss is:  2159.81170959\n",
      "In  8  th episode,  35  th iteration, the average loss is:  50656.1002785\n",
      "In  8  th episode,  36  th iteration, the average loss is:  6674.54342194\n",
      "In  8  th episode,  37  th iteration, the average loss is:  18267.078107\n",
      "In  8  th episode,  38  th iteration, the average loss is:  14093.5822798\n",
      "In  8  th episode,  39  th iteration, the average loss is:  10736.0852621\n",
      "In  8  th episode,  40  th iteration, the average loss is:  34085.6488892\n",
      "In  8  th episode,  41  th iteration, the average loss is:  88488.9712165\n",
      "In  8  th episode,  42  th iteration, the average loss is:  3527.48846893\n",
      "In  8  th episode,  43  th iteration, the average loss is:  76069.7577773\n",
      "In  8  th episode,  44  th iteration, the average loss is:  89748.0092808\n",
      "In  8  th episode,  45  th iteration, the average loss is:  19220.1497831\n",
      "In  8  th episode,  46  th iteration, the average loss is:  59581.9098969\n",
      "In  8  th episode,  47  th iteration, the average loss is:  22411.3669373\n",
      "In  8  th episode,  48  th iteration, the average loss is:  58014.6547974\n",
      "In  8  th episode,  49  th iteration, the average loss is:  40425.5952744\n",
      "In  8  th episode,  50  th iteration, the average loss is:  52413.9518916\n",
      "In  8  th episode,  51  th iteration, the average loss is:  543635.576465\n",
      "In  8  th episode,  52  th iteration, the average loss is:  45821.3109497\n",
      "In  8  th episode,  53  th iteration, the average loss is:  240108.591557\n",
      "In  8  th episode,  54  th iteration, the average loss is:  32105.2215347\n",
      "In  8  th episode,  55  th iteration, the average loss is:  54700.2066986\n",
      "In  8  th episode,  56  th iteration, the average loss is:  2998.02320786\n",
      "In  8  th episode,  57  th iteration, the average loss is:  20251.841893\n",
      "In  8  th episode,  58  th iteration, the average loss is:  149930.346497\n",
      "In  8  th episode,  59  th iteration, the average loss is:  5027.15137939\n",
      "In  8  th episode,  60  th iteration, the average loss is:  38830.0811844\n",
      "In  8  th episode,  61  th iteration, the average loss is:  90201.0352509\n",
      "In  8  th episode,  62  th iteration, the average loss is:  4311.05830231\n",
      "In  8  th episode,  63  th iteration, the average loss is:  8848.61591516\n",
      "In  8  th episode,  64  th iteration, the average loss is:  61188.825426\n",
      "In  8  th episode,  65  th iteration, the average loss is:  272751.883426\n",
      "In  8  th episode,  66  th iteration, the average loss is:  6827.60811462\n",
      "In  8  th episode,  67  th iteration, the average loss is:  49979.2024902\n",
      "In  8  th episode,  68  th iteration, the average loss is:  27529.5537079\n",
      "In  8  th episode,  69  th iteration, the average loss is:  69029.0227295\n",
      "In  8  th episode,  70  th iteration, the average loss is:  23681.66146\n",
      "In  8  th episode,  71  th iteration, the average loss is:  4787.46545151\n",
      "In  8  th episode,  72  th iteration, the average loss is:  18950.0121811\n",
      "In  8  th episode,  73  th iteration, the average loss is:  22842.4674255\n",
      "In  8  th episode,  74  th iteration, the average loss is:  26857.0039856\n",
      "In  8  th episode,  75  th iteration, the average loss is:  38592.1095467\n",
      "In  8  th episode,  76  th iteration, the average loss is:  5243.04514928\n",
      "In  8  th episode,  77  th iteration, the average loss is:  20944.4897903\n",
      "In  8  th episode,  78  th iteration, the average loss is:  13107.8981426\n",
      "In  8  th episode,  79  th iteration, the average loss is:  2879.81583862\n",
      "In  8  th episode,  80  th iteration, the average loss is:  2825.70815887\n",
      "In  8  th episode,  81  th iteration, the average loss is:  8361.9258873\n",
      "In  8  th episode,  82  th iteration, the average loss is:  1619.42617035\n",
      "In  8  th episode,  83  th iteration, the average loss is:  116867.104743\n",
      "In  8  th episode,  84  th iteration, the average loss is:  84092.2980826\n",
      "In  8  th episode,  85  th iteration, the average loss is:  18975.8412476\n",
      "In  8  th episode,  86  th iteration, the average loss is:  35727.5061382\n",
      "In  8  th episode,  87  th iteration, the average loss is:  17806.9282864\n",
      "In  8  th episode,  88  th iteration, the average loss is:  12627.5272858\n",
      "In  8  th episode,  89  th iteration, the average loss is:  10427.250885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  8  th episode,  90  th iteration, the average loss is:  13992.3112922\n",
      "In  8  th episode,  91  th iteration, the average loss is:  23196.5819458\n",
      "In  8  th episode,  92  th iteration, the average loss is:  44966.7941206\n",
      "In  8  th episode,  93  th iteration, the average loss is:  3328.16059341\n",
      "In  8  th episode,  94  th iteration, the average loss is:  19446.3549103\n",
      "In  8  th episode,  95  th iteration, the average loss is:  31526.024115\n",
      "In  8  th episode,  96  th iteration, the average loss is:  23249.0417765\n",
      "In  8  th episode,  97  th iteration, the average loss is:  3366.19024811\n",
      "In  8  th episode,  98  th iteration, the average loss is:  9492.46069827\n",
      "In  8  th episode,  99  th iteration, the average loss is:  27815.2100954\n",
      "In  8  th episode,  100  th iteration, the average loss is:  32082.7316452\n",
      "In  9  th episode,  1  th iteration, the average loss is:  9550.99504957\n",
      "In  9  th episode,  2  th iteration, the average loss is:  4809.07836965\n",
      "In  9  th episode,  3  th iteration, the average loss is:  57077.2614304\n",
      "In  9  th episode,  4  th iteration, the average loss is:  28107.1375732\n",
      "In  9  th episode,  5  th iteration, the average loss is:  4347.96639404\n",
      "In  9  th episode,  6  th iteration, the average loss is:  7867.39511448\n",
      "In  9  th episode,  7  th iteration, the average loss is:  56936.1862877\n",
      "In  9  th episode,  8  th iteration, the average loss is:  10239.9014692\n",
      "In  9  th episode,  9  th iteration, the average loss is:  60797.9869843\n",
      "In  9  th episode,  10  th iteration, the average loss is:  9050.36097267\n",
      "In  9  th episode,  11  th iteration, the average loss is:  62927.7374159\n",
      "In  9  th episode,  12  th iteration, the average loss is:  257333.936446\n",
      "In  9  th episode,  13  th iteration, the average loss is:  29652.776268\n",
      "In  9  th episode,  14  th iteration, the average loss is:  103433.690118\n",
      "In  9  th episode,  15  th iteration, the average loss is:  53466.3527908\n",
      "In  9  th episode,  16  th iteration, the average loss is:  242689.173328\n",
      "In  9  th episode,  17  th iteration, the average loss is:  60189.9318119\n",
      "In  9  th episode,  18  th iteration, the average loss is:  7066.52001419\n",
      "In  9  th episode,  19  th iteration, the average loss is:  78401.6670102\n",
      "In  9  th episode,  20  th iteration, the average loss is:  7760.59742184\n",
      "In  9  th episode,  21  th iteration, the average loss is:  15495.4569145\n",
      "In  9  th episode,  22  th iteration, the average loss is:  4342.3405405\n",
      "In  9  th episode,  23  th iteration, the average loss is:  10763.2793304\n",
      "In  9  th episode,  24  th iteration, the average loss is:  35707.1733704\n",
      "In  9  th episode,  25  th iteration, the average loss is:  38712.2491234\n",
      "In  9  th episode,  26  th iteration, the average loss is:  9544.84796205\n",
      "In  9  th episode,  27  th iteration, the average loss is:  18136.952039\n",
      "In  9  th episode,  28  th iteration, the average loss is:  2950.07131405\n",
      "In  9  th episode,  29  th iteration, the average loss is:  4204.43504318\n",
      "In  9  th episode,  30  th iteration, the average loss is:  2568.72656614\n",
      "In  9  th episode,  31  th iteration, the average loss is:  178208.820449\n",
      "In  9  th episode,  32  th iteration, the average loss is:  8825.52775879\n",
      "In  9  th episode,  33  th iteration, the average loss is:  2577.98065529\n",
      "In  9  th episode,  34  th iteration, the average loss is:  15160.3604441\n",
      "In  9  th episode,  35  th iteration, the average loss is:  22856.7581543\n",
      "In  9  th episode,  36  th iteration, the average loss is:  137617.591443\n",
      "In  9  th episode,  37  th iteration, the average loss is:  59705.2222536\n",
      "In  9  th episode,  38  th iteration, the average loss is:  33748.1220404\n",
      "In  9  th episode,  39  th iteration, the average loss is:  18477.9893036\n",
      "In  9  th episode,  40  th iteration, the average loss is:  26537.9876068\n",
      "In  9  th episode,  41  th iteration, the average loss is:  61731.4328396\n",
      "In  9  th episode,  42  th iteration, the average loss is:  155183.252725\n",
      "In  9  th episode,  43  th iteration, the average loss is:  28473.1228603\n",
      "In  9  th episode,  44  th iteration, the average loss is:  11734.9648758\n",
      "In  9  th episode,  45  th iteration, the average loss is:  34018.4672535\n",
      "In  9  th episode,  46  th iteration, the average loss is:  12971.4284058\n",
      "In  9  th episode,  47  th iteration, the average loss is:  183960.718578\n",
      "In  9  th episode,  48  th iteration, the average loss is:  7411.28350754\n",
      "In  9  th episode,  49  th iteration, the average loss is:  7605.22649536\n",
      "In  9  th episode,  50  th iteration, the average loss is:  5057.81137013\n",
      "In  9  th episode,  51  th iteration, the average loss is:  12309.1544922\n",
      "In  9  th episode,  52  th iteration, the average loss is:  255784.405141\n",
      "In  9  th episode,  53  th iteration, the average loss is:  2680.24934807\n",
      "In  9  th episode,  54  th iteration, the average loss is:  47183.453955\n",
      "In  9  th episode,  55  th iteration, the average loss is:  46847.427679\n",
      "In  9  th episode,  56  th iteration, the average loss is:  3128.42080154\n",
      "In  9  th episode,  57  th iteration, the average loss is:  3372.60312023\n",
      "In  9  th episode,  58  th iteration, the average loss is:  12801.0642357\n",
      "In  9  th episode,  59  th iteration, the average loss is:  24126.1874672\n",
      "In  9  th episode,  60  th iteration, the average loss is:  117323.804306\n",
      "In  9  th episode,  61  th iteration, the average loss is:  8645.69628811\n",
      "In  9  th episode,  62  th iteration, the average loss is:  1473.66919498\n",
      "In  9  th episode,  63  th iteration, the average loss is:  36853.82286\n",
      "In  9  th episode,  64  th iteration, the average loss is:  2114.31967239\n",
      "In  9  th episode,  65  th iteration, the average loss is:  57237.9531769\n",
      "In  9  th episode,  66  th iteration, the average loss is:  2322.6271183\n",
      "In  9  th episode,  67  th iteration, the average loss is:  44094.2358902\n",
      "In  9  th episode,  68  th iteration, the average loss is:  10884.1069702\n",
      "In  9  th episode,  69  th iteration, the average loss is:  18824.5450097\n",
      "In  9  th episode,  70  th iteration, the average loss is:  7219.64851074\n",
      "In  9  th episode,  71  th iteration, the average loss is:  11151.4363933\n",
      "In  9  th episode,  72  th iteration, the average loss is:  22449.1796909\n",
      "In  9  th episode,  73  th iteration, the average loss is:  3495.47807198\n",
      "In  9  th episode,  74  th iteration, the average loss is:  5035.50786543\n",
      "In  9  th episode,  75  th iteration, the average loss is:  2353.02106724\n",
      "In  9  th episode,  76  th iteration, the average loss is:  1991.23538685\n",
      "In  9  th episode,  77  th iteration, the average loss is:  6723.43653564\n",
      "In  9  th episode,  78  th iteration, the average loss is:  3004.11439209\n",
      "In  9  th episode,  79  th iteration, the average loss is:  715.911196327\n",
      "In  9  th episode,  80  th iteration, the average loss is:  1899.25356445\n",
      "In  9  th episode,  81  th iteration, the average loss is:  31620.2489553\n",
      "In  9  th episode,  82  th iteration, the average loss is:  1296.18794239\n",
      "In  9  th episode,  83  th iteration, the average loss is:  1750.61835937\n",
      "In  9  th episode,  84  th iteration, the average loss is:  129958.846947\n",
      "In  9  th episode,  85  th iteration, the average loss is:  1006.10725451\n",
      "In  9  th episode,  86  th iteration, the average loss is:  92002.6500842\n",
      "In  9  th episode,  87  th iteration, the average loss is:  26355.4831379\n",
      "In  9  th episode,  88  th iteration, the average loss is:  2765.66955128\n",
      "In  9  th episode,  89  th iteration, the average loss is:  9851.26466904\n",
      "In  9  th episode,  90  th iteration, the average loss is:  1348.84547043\n",
      "In  9  th episode,  91  th iteration, the average loss is:  1673.31665235\n",
      "In  9  th episode,  92  th iteration, the average loss is:  2401.7051815\n",
      "In  9  th episode,  93  th iteration, the average loss is:  25719.55661\n",
      "In  9  th episode,  94  th iteration, the average loss is:  2392.78642775\n",
      "In  9  th episode,  95  th iteration, the average loss is:  434.160843015\n",
      "In  9  th episode,  96  th iteration, the average loss is:  7383.73389969\n",
      "In  9  th episode,  97  th iteration, the average loss is:  372.801693513\n",
      "In  9  th episode,  98  th iteration, the average loss is:  7583.09939117\n",
      "In  9  th episode,  99  th iteration, the average loss is:  28428.4733681\n",
      "In  9  th episode,  100  th iteration, the average loss is:  5327.93261939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In  10  th episode,  1  th iteration, the average loss is:  1855.24678802\n",
      "In  10  th episode,  2  th iteration, the average loss is:  1049.12473033\n",
      "In  10  th episode,  3  th iteration, the average loss is:  1143.07083893\n",
      "In  10  th episode,  4  th iteration, the average loss is:  3386.37470207\n",
      "In  10  th episode,  5  th iteration, the average loss is:  870.196243286\n",
      "In  10  th episode,  6  th iteration, the average loss is:  402.712975025\n",
      "In  10  th episode,  7  th iteration, the average loss is:  9415.07217196\n",
      "In  10  th episode,  8  th iteration, the average loss is:  519.325942516\n",
      "In  10  th episode,  9  th iteration, the average loss is:  4686.7429636\n",
      "In  10  th episode,  10  th iteration, the average loss is:  266.991323966\n",
      "In  10  th episode,  11  th iteration, the average loss is:  1665.96327524\n",
      "In  10  th episode,  12  th iteration, the average loss is:  566.461627173\n",
      "In  10  th episode,  13  th iteration, the average loss is:  56218.0461438\n",
      "In  10  th episode,  14  th iteration, the average loss is:  34574.9931408\n",
      "In  10  th episode,  15  th iteration, the average loss is:  23068.5562239\n",
      "In  10  th episode,  16  th iteration, the average loss is:  2463.9314724\n",
      "In  10  th episode,  17  th iteration, the average loss is:  22032.6886696\n",
      "In  10  th episode,  18  th iteration, the average loss is:  52981.870121\n",
      "In  10  th episode,  19  th iteration, the average loss is:  13528.5695689\n",
      "In  10  th episode,  20  th iteration, the average loss is:  1344.83611698\n",
      "In  10  th episode,  21  th iteration, the average loss is:  8535.83288651\n",
      "In  10  th episode,  22  th iteration, the average loss is:  24529.4218108\n",
      "In  10  th episode,  23  th iteration, the average loss is:  17280.2912766\n",
      "In  10  th episode,  24  th iteration, the average loss is:  1715.0686142\n",
      "In  10  th episode,  25  th iteration, the average loss is:  42825.2494526\n",
      "In  10  th episode,  26  th iteration, the average loss is:  44122.5072\n",
      "In  10  th episode,  27  th iteration, the average loss is:  2314.46595001\n",
      "In  10  th episode,  28  th iteration, the average loss is:  17616.6240105\n",
      "In  10  th episode,  29  th iteration, the average loss is:  8035.41765785\n",
      "In  10  th episode,  30  th iteration, the average loss is:  4714.73569183\n",
      "In  10  th episode,  31  th iteration, the average loss is:  5006.69687992\n",
      "In  10  th episode,  32  th iteration, the average loss is:  5968.38892918\n",
      "In  10  th episode,  33  th iteration, the average loss is:  220280.551741\n",
      "In  10  th episode,  34  th iteration, the average loss is:  4219.43464618\n",
      "In  10  th episode,  35  th iteration, the average loss is:  3499.4395752\n",
      "In  10  th episode,  36  th iteration, the average loss is:  4653.51611633\n",
      "In  10  th episode,  37  th iteration, the average loss is:  3416.2083675\n",
      "In  10  th episode,  38  th iteration, the average loss is:  42201.8184836\n",
      "In  10  th episode,  39  th iteration, the average loss is:  1035.70146112\n",
      "In  10  th episode,  40  th iteration, the average loss is:  15384.6697723\n",
      "In  10  th episode,  41  th iteration, the average loss is:  2681.77033677\n",
      "In  10  th episode,  42  th iteration, the average loss is:  3200.11186829\n",
      "In  10  th episode,  43  th iteration, the average loss is:  1749.52191272\n",
      "In  10  th episode,  44  th iteration, the average loss is:  33944.0056232\n",
      "In  10  th episode,  45  th iteration, the average loss is:  2447.91181183\n",
      "In  10  th episode,  46  th iteration, the average loss is:  33247.1741669\n",
      "In  10  th episode,  47  th iteration, the average loss is:  1873.67405968\n",
      "In  10  th episode,  48  th iteration, the average loss is:  1247.78646317\n",
      "In  10  th episode,  49  th iteration, the average loss is:  4584.04780335\n",
      "In  10  th episode,  50  th iteration, the average loss is:  1917.82765153\n",
      "In  10  th episode,  51  th iteration, the average loss is:  643.476206207\n",
      "In  10  th episode,  52  th iteration, the average loss is:  51641.1447273\n",
      "In  10  th episode,  53  th iteration, the average loss is:  3617.14432176\n",
      "In  10  th episode,  54  th iteration, the average loss is:  1992.78084086\n",
      "In  10  th episode,  55  th iteration, the average loss is:  913.868630505\n",
      "In  10  th episode,  56  th iteration, the average loss is:  2027.74871197\n",
      "In  10  th episode,  57  th iteration, the average loss is:  696.462533569\n",
      "In  10  th episode,  58  th iteration, the average loss is:  1027.49896736\n",
      "In  10  th episode,  59  th iteration, the average loss is:  2880.81068611\n",
      "In  10  th episode,  60  th iteration, the average loss is:  1534.33636656\n",
      "In  10  th episode,  61  th iteration, the average loss is:  1333.55224533\n",
      "In  10  th episode,  62  th iteration, the average loss is:  382.889870501\n",
      "In  10  th episode,  63  th iteration, the average loss is:  1599.26454124\n",
      "In  10  th episode,  64  th iteration, the average loss is:  1065.0302101\n",
      "In  10  th episode,  65  th iteration, the average loss is:  436.776058388\n",
      "In  10  th episode,  66  th iteration, the average loss is:  666.750675201\n",
      "In  10  th episode,  67  th iteration, the average loss is:  611.523233435\n",
      "In  10  th episode,  68  th iteration, the average loss is:  1317.75540698\n",
      "In  10  th episode,  69  th iteration, the average loss is:  595.685606766\n",
      "In  10  th episode,  70  th iteration, the average loss is:  584.406628418\n",
      "In  10  th episode,  71  th iteration, the average loss is:  6997.00960541\n",
      "In  10  th episode,  72  th iteration, the average loss is:  16580.7337395\n",
      "In  10  th episode,  73  th iteration, the average loss is:  31223.0617737\n",
      "In  10  th episode,  74  th iteration, the average loss is:  1501.32561188\n",
      "In  10  th episode,  75  th iteration, the average loss is:  4456.6153862\n",
      "In  10  th episode,  76  th iteration, the average loss is:  30576.9117279\n",
      "In  10  th episode,  77  th iteration, the average loss is:  56683.9137289\n",
      "In  10  th episode,  78  th iteration, the average loss is:  1102.50694451\n",
      "In  10  th episode,  79  th iteration, the average loss is:  24697.5853589\n",
      "In  10  th episode,  80  th iteration, the average loss is:  1450.64050488\n",
      "In  10  th episode,  81  th iteration, the average loss is:  1142.47130275\n",
      "In  10  th episode,  82  th iteration, the average loss is:  623.75932085\n",
      "In  10  th episode,  83  th iteration, the average loss is:  892.252631199\n",
      "In  10  th episode,  84  th iteration, the average loss is:  53.92206738\n",
      "In  10  th episode,  85  th iteration, the average loss is:  23462.1740482\n",
      "In  10  th episode,  86  th iteration, the average loss is:  235.537776469\n",
      "In  10  th episode,  87  th iteration, the average loss is:  236.393609715\n",
      "In  10  th episode,  88  th iteration, the average loss is:  768.593555462\n",
      "In  10  th episode,  89  th iteration, the average loss is:  653.371194839\n",
      "In  10  th episode,  90  th iteration, the average loss is:  172.70106287\n",
      "In  10  th episode,  91  th iteration, the average loss is:  308.810757136\n",
      "In  10  th episode,  92  th iteration, the average loss is:  374.505026937\n",
      "In  10  th episode,  93  th iteration, the average loss is:  26880.6918602\n",
      "In  10  th episode,  94  th iteration, the average loss is:  1096.01485729\n",
      "In  10  th episode,  95  th iteration, the average loss is:  21272.2745262\n",
      "In  10  th episode,  96  th iteration, the average loss is:  1014.67190628\n",
      "In  10  th episode,  97  th iteration, the average loss is:  4000.68439468\n",
      "In  10  th episode,  98  th iteration, the average loss is:  453.090729745\n",
      "In  10  th episode,  99  th iteration, the average loss is:  1363.59485684\n",
      "In  10  th episode,  100  th iteration, the average loss is:  1770.76279755\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 10\n",
    "ITERATIONS = 100\n",
    "\n",
    "agent = DQNAgent()\n",
    "batch_size = 10\n",
    "\n",
    "for e in range(1,EPISODES+1):\n",
    "    robot = ThreeLinkRobot()\n",
    "    state = robot.randomize_state()\n",
    "    for i in range(1,ITERATIONS+1):\n",
    "        # print('In ', e, ' th epsiode, ', i, ' th iteration, the initial state is: ', state)\n",
    "        action = agent.choose_action(robot, state, epsilon_greedy=True)\n",
    "        # print('In ', e, ' th epsiode, ', i, ' th iteration, the chosen action is: ', action)\n",
    "        robot_after_transition, reward, next_state = agent.act(robot, action)\n",
    "        # print('In ', e, ' th epsiode, ', i, ' th iteration, the state after transition is: ', next_state)\n",
    "        agent.remember(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        robot = robot_after_transition\n",
    "        if len(agent.memory) > batch_size:\n",
    "            avg_loss = agent.replay(batch_size)\n",
    "            print('In ', e, ' th episode, ', i, ' th iteration, the average loss is: ', avg_loss)\n",
    "            \n",
    "        # print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_graphs(xs, a1s, a2s, steps):\n",
    "    \n",
    "    # plotting\n",
    "    fig1 = plt.figure(1)\n",
    "    fig1.suptitle('Policy Rollout')\n",
    "    ax1 = fig1.add_subplot(311)\n",
    "    ax2 = fig1.add_subplot(312)\n",
    "    ax3 = fig1.add_subplot(313)\n",
    "    fig2 = plt.figure(2)\n",
    "    fig2.suptitle('a1 vs a2')\n",
    "    ax4 = fig2.add_subplot(111)\n",
    "    \n",
    "    ax1.plot(steps, xs, '.-')\n",
    "    ax1.set_ylabel('x')\n",
    "    ax1.set_xlabel('steps')\n",
    "    ax2.plot(steps, a1s, '.-')\n",
    "    ax2.set_ylabel('a1')\n",
    "    ax2.set_xlabel('steps')\n",
    "    ax3.plot(steps, a2s, '.-')\n",
    "    ax3.set_ylabel('a2')\n",
    "    ax3.set_xlabel('steps')\n",
    "    ax4.plot(a1s,a2s,'.-')\n",
    "    ax4.set_xlabel('a1')\n",
    "    ax4.set_ylabel('a2')\n",
    "    \n",
    "    fig1.tight_layout()\n",
    "    fig2.tight_layout()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1 th iteration the initial state is:  (0, 0.19634954084936207, -0.19634954084936207)\n",
      "In 1 th iteration the chosen action is:  (0.024543692606170259, -0.19634954084936207)\n",
      "In 1 th iteration, the robot moved  0.44274120520315774  in x direction\n",
      "In 2 th iteration the initial state is:  (0.03121531258256096, 0.22089323345553233, -0.39269908169872414)\n",
      "In 2 th iteration the chosen action is:  (0.024543692606170259, -0.19634954084936207)\n",
      "In 2 th iteration, the robot moved  0.29190630514636595  in x direction\n",
      "In 3 th iteration the initial state is:  (0.051180120357766395, 0.2454369260617026, -0.5890486225480862)\n",
      "In 3 th iteration the chosen action is:  (0.024543692606170259, -0.19634954084936207)\n",
      "In 3 th iteration, the robot moved  0.22479373593592644  in x direction\n",
      "In 4 th iteration the initial state is:  (0.06648360572096443, 0.2699806186678728, -0.7853981633974483)\n",
      "In 4 th iteration the chosen action is:  (0.024543692606170259, -0.19634954084936207)\n",
      "In 4 th iteration, the robot moved  0.18930542116857063  in x direction\n",
      "In 5 th iteration the initial state is:  (0.07975307653731091, 0.2945243112740431, -0.9817477042468103)\n",
      "In 5 th iteration the chosen action is:  (0.024543692606170259, -0.19634954084936207)\n",
      "In 5 th iteration, the robot moved  0.16958179934096695  in x direction\n",
      "In 6 th iteration the initial state is:  (0.09244650223055155, 0.3190680038802134, -1.1780972450961724)\n",
      "In 6 th iteration the chosen action is:  (0.024543692606170259, -0.19634954084936207)\n",
      "In 6 th iteration, the robot moved  0.15936231876699836  in x direction\n",
      "In 7 th iteration the initial state is:  (0.1056085239836701, 0.3436116964863837, -1.3744467859455345)\n",
      "In 7 th iteration the chosen action is:  (0.024543692606170259, -0.19634954084936207)\n",
      "In 7 th iteration, the robot moved  0.15592609750631015  in x direction\n",
      "In 8 th iteration the initial state is:  (0.12017452475950824, 0.36815538909255396, -1.5707963267948966)\n",
      "In 8 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 8 th iteration, the robot moved  0.006090349359534342  in x direction\n",
      "In 9 th iteration the initial state is:  (0.1340139464338156, 0.3436116964863837, -1.5707963267948966)\n",
      "In 9 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 9 th iteration, the robot moved  0.006455039599348789  in x direction\n",
      "In 10 th iteration the initial state is:  (0.1477854624119632, 0.3190680038802134, -1.5707963267948966)\n",
      "In 10 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 10 th iteration, the robot moved  0.006820360501983647  in x direction\n",
      "In 11 th iteration the initial state is:  (0.16148451688778576, 0.2945243112740431, -1.5707963267948966)\n",
      "In 11 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 11 th iteration, the robot moved  0.007186336124546999  in x direction\n",
      "In 12 th iteration the initial state is:  (0.1751064315392195, 0.2699806186678728, -1.5707963267948966)\n",
      "In 12 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 12 th iteration, the robot moved  0.0075530010012641036  in x direction\n",
      "In 13 th iteration the initial state is:  (0.18864639601633135, 0.24543692606170256, -1.5707963267948966)\n",
      "In 13 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 13 th iteration, the robot moved  0.00792040102403302  in x direction\n",
      "In 14 th iteration the initial state is:  (0.20209945789231437, 0.2208932334555323, -1.5707963267948966)\n",
      "In 14 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 14 th iteration, the robot moved  0.008288594384632475  in x direction\n",
      "In 15 th iteration the initial state is:  (0.21546051202641722, 0.19634954084936204, -1.5707963267948966)\n",
      "In 15 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 15 th iteration, the robot moved  0.00865765258525597  in x direction\n",
      "In 16 th iteration the initial state is:  (0.22872428928316213, 0.17180584824319178, -1.5707963267948966)\n",
      "In 16 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 16 th iteration, the robot moved  0.0090276615248015  in x direction\n",
      "In 17 th iteration the initial state is:  (0.2418853445470475, 0.14726215563702152, -1.5707963267948966)\n",
      "In 17 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 17 th iteration, the robot moved  0.00939872266918429  in x direction\n",
      "In 18 th iteration the initial state is:  (0.2549380439661556, 0.12271846303085127, -1.5707963267948966)\n",
      "In 18 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 18 th iteration, the robot moved  0.009770954314897162  in x direction\n",
      "In 19 th iteration the initial state is:  (0.2678765513516163, 0.09817477042468101, -1.5707963267948966)\n",
      "In 19 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 19 th iteration, the robot moved  0.010144492956129625  in x direction\n",
      "In 20 th iteration the initial state is:  (0.2806948136526216, 0.07363107781851075, -1.5707963267948966)\n",
      "In 20 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 20 th iteration, the robot moved  0.010519494766991766  in x direction\n",
      "In 21 th iteration the initial state is:  (0.29338654541854375, 0.04908738521234049, -1.5707963267948966)\n",
      "In 21 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 21 th iteration, the robot moved  0.010896137211792833  in x direction\n",
      "In 22 th iteration the initial state is:  (0.3059452121505546, 0.02454369260617023, -1.5707963267948966)\n",
      "In 22 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 22 th iteration, the robot moved  0.011274620797923074  in x direction\n",
      "In 23 th iteration the initial state is:  (0.31836401243484425, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 23 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 23 th iteration, the robot moved  0.011655170987718622  in x direction\n",
      "In 24 th iteration the initial state is:  (0.3306358587379294, -0.024543692606170286, -1.5707963267948966)\n",
      "In 24 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 24 th iteration, the robot moved  0.012038040287775997  in x direction\n",
      "In 25 th iteration the initial state is:  (0.3427533567314374, -0.049087385212340545, -1.5707963267948966)\n",
      "In 25 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 25 th iteration, the robot moved  0.012423510536575089  in x direction\n",
      "In 26 th iteration the initial state is:  (0.35470878299894343, -0.0736310778185108, -1.5707963267948966)\n",
      "In 26 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 26 th iteration, the robot moved  0.012811895414016394  in x direction\n",
      "In 27 th iteration the initial state is:  (0.366494060960662, -0.09817477042468106, -1.5707963267948966)\n",
      "In 27 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 27 th iteration, the robot moved  0.013203543199631573  in x direction\n",
      "In 28 th iteration the initial state is:  (0.37810073483277007, -0.12271846303085132, -1.5707963267948966)\n",
      "In 28 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 28 th iteration, the robot moved  -0.10879071847889343  in x direction\n",
      "In 29 th iteration the initial state is:  (0.28674708216284794, 0.07363107781851075, -1.5707963267948966)\n",
      "In 29 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 29 th iteration, the robot moved  0.010500946645642273  in x direction\n",
      "In 30 th iteration the initial state is:  (0.2994388139287701, 0.04908738521234049, -1.5707963267948966)\n",
      "In 30 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 30 th iteration, the robot moved  0.010876015073134404  in x direction\n",
      "In 31 th iteration the initial state is:  (0.3119974806607809, 0.02454369260617023, -1.5707963267948966)\n",
      "In 31 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 31 th iteration, the robot moved  0.011252860920726748  in x direction\n",
      "In 32 th iteration the initial state is:  (0.3244162809450706, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 32 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 32 th iteration, the robot moved  0.011631709390191869  in x direction\n",
      "In 33 th iteration the initial state is:  (0.3366881272481557, -0.024543692606170286, -1.5707963267948966)\n",
      "In 33 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 33 th iteration, the robot moved  0.012012812701964748  in x direction\n",
      "In 34 th iteration the initial state is:  (0.34880562524166375, -0.049087385212340545, -1.5707963267948966)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 34 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 34 th iteration, the robot moved  0.012396452380907697  in x direction\n",
      "In 35 th iteration the initial state is:  (0.36076105150916976, -0.0736310778185108, -1.5707963267948966)\n",
      "In 35 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 35 th iteration, the robot moved  0.012782941763975098  in x direction\n",
      "In 36 th iteration the initial state is:  (0.37254632947088834, -0.09817477042468106, -1.5707963267948966)\n",
      "In 36 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 36 th iteration, the robot moved  0.01317262875656633  in x direction\n",
      "In 37 th iteration the initial state is:  (0.3841530033429964, -0.12271846303085132, -1.5707963267948966)\n",
      "In 37 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 37 th iteration, the robot moved  -0.10852719094384033  in x direction\n",
      "In 38 th iteration the initial state is:  (0.2927993506730743, 0.07363107781851075, -1.5707963267948966)\n",
      "In 38 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 38 th iteration, the robot moved  0.010482013876273122  in x direction\n",
      "In 39 th iteration the initial state is:  (0.3054910824389964, 0.04908738521234049, -1.5707963267948966)\n",
      "In 39 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 39 th iteration, the robot moved  0.010855494547758582  in x direction\n",
      "In 40 th iteration the initial state is:  (0.31804974917100726, 0.02454369260617023, -1.5707963267948966)\n",
      "In 40 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 40 th iteration, the robot moved  0.011230688853009374  in x direction\n",
      "In 41 th iteration the initial state is:  (0.3304685494552969, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 41 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 41 th iteration, the robot moved  0.011607821724984202  in x direction\n",
      "In 42 th iteration the initial state is:  (0.34274039575838205, -0.024543692606170286, -1.5707963267948966)\n",
      "In 42 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 42 th iteration, the robot moved  0.011987145088718787  in x direction\n",
      "In 43 th iteration the initial state is:  (0.3548578937518901, -0.049087385212340545, -1.5707963267948966)\n",
      "In 43 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 43 th iteration, the robot moved  0.012368940145144336  in x direction\n",
      "In 44 th iteration the initial state is:  (0.3668133200193961, -0.0736310778185108, -1.5707963267948966)\n",
      "In 44 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 44 th iteration, the robot moved  0.01275351987679274  in x direction\n",
      "In 45 th iteration the initial state is:  (0.37859859798111467, -0.09817477042468106, -1.5707963267948966)\n",
      "In 45 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 45 th iteration, the robot moved  0.013141231802186848  in x direction\n",
      "In 46 th iteration the initial state is:  (0.39020527185322273, -0.12271846303085132, -1.5707963267948966)\n",
      "In 46 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 46 th iteration, the robot moved  -0.10825968807489716  in x direction\n",
      "In 47 th iteration the initial state is:  (0.2988516191833006, 0.07363107781851075, -1.5707963267948966)\n",
      "In 47 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 47 th iteration, the robot moved  0.010462697152388678  in x direction\n",
      "In 48 th iteration the initial state is:  (0.31154335094922275, 0.04908738521234049, -1.5707963267948966)\n",
      "In 48 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 48 th iteration, the robot moved  0.010834576387329431  in x direction\n",
      "In 49 th iteration the initial state is:  (0.3241020176812336, 0.02454369260617023, -1.5707963267948966)\n",
      "In 49 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 49 th iteration, the robot moved  0.011208105406930402  in x direction\n",
      "In 50 th iteration the initial state is:  (0.33652081796552324, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 50 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 50 th iteration, the robot moved  0.01158350886709747  in x direction\n",
      "In 51 th iteration the initial state is:  (0.3487926642686084, -0.024543692606170286, -1.5707963267948966)\n",
      "In 51 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 51 th iteration, the robot moved  0.011961038388238254  in x direction\n",
      "In 52 th iteration the initial state is:  (0.3609101622621164, -0.049087385212340545, -1.5707963267948966)\n",
      "In 52 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 52 th iteration, the robot moved  0.012340974837053986  in x direction\n",
      "In 53 th iteration the initial state is:  (0.3728655885296224, -0.0736310778185108, -1.5707963267948966)\n",
      "In 53 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 53 th iteration, the robot moved  0.012723630830188348  in x direction\n",
      "In 54 th iteration the initial state is:  (0.384650866491341, -0.09817477042468106, -1.5707963267948966)\n",
      "In 54 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 54 th iteration, the robot moved  0.013109353486558728  in x direction\n",
      "In 55 th iteration the initial state is:  (0.39625754036344907, -0.12271846303085132, -1.5707963267948966)\n",
      "In 55 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 55 th iteration, the robot moved  -0.10798821967065142  in x direction\n",
      "In 56 th iteration the initial state is:  (0.30490388769352694, 0.07363107781851075, -1.5707963267948966)\n",
      "In 56 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 56 th iteration, the robot moved  0.01044299718155739  in x direction\n",
      "In 57 th iteration the initial state is:  (0.3175956194594491, 0.04908738521234049, -1.5707963267948966)\n",
      "In 57 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 57 th iteration, the robot moved  0.01081326135807581  in x direction\n",
      "In 58 th iteration the initial state is:  (0.3301542861914599, 0.02454369260617023, -1.5707963267948966)\n",
      "In 58 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 58 th iteration, the robot moved  0.011185111409717674  in x direction\n",
      "In 59 th iteration the initial state is:  (0.3425730864757496, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 59 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 59 th iteration, the robot moved  0.011558771707107285  in x direction\n",
      "In 60 th iteration the initial state is:  (0.3548449327788347, -0.024543692606170286, -1.5707963267948966)\n",
      "In 60 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 60 th iteration, the robot moved  0.011934493556807979  in x direction\n",
      "In 61 th iteration the initial state is:  (0.36696243077234275, -0.049087385212340545, -1.5707963267948966)\n",
      "In 61 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 61 th iteration, the robot moved  0.012312557481001463  in x direction\n",
      "In 62 th iteration the initial state is:  (0.37891785703984876, -0.0736310778185108, -1.5707963267948966)\n",
      "In 62 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 62 th iteration, the robot moved  0.012693275718993036  in x direction\n",
      "In 63 th iteration the initial state is:  (0.39070313500156734, -0.09817477042468106, -1.5707963267948966)\n",
      "In 63 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 63 th iteration, the robot moved  0.013076994977379686  in x direction\n",
      "In 64 th iteration the initial state is:  (0.4023098088736754, -0.12271846303085132, -1.5707963267948966)\n",
      "In 64 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 64 th iteration, the robot moved  -0.10771279567494818  in x direction\n",
      "In 65 th iteration the initial state is:  (0.3109561562037533, 0.07363107781851075, -1.5707963267948966)\n",
      "In 65 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 65 th iteration, the robot moved  0.010422914685386031  in x direction\n",
      "In 66 th iteration the initial state is:  (0.3236478879696754, 0.04908738521234049, -1.5707963267948966)\n",
      "In 66 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 66 th iteration, the robot moved  0.010791550240763614  in x direction\n",
      "In 67 th iteration the initial state is:  (0.33620655470168626, 0.02454369260617023, -1.5707963267948966)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 67 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 67 th iteration, the robot moved  0.011161707703637891  in x direction\n",
      "In 68 th iteration the initial state is:  (0.3486253549859759, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 68 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 68 th iteration, the robot moved  0.011533611151132384  in x direction\n",
      "In 69 th iteration the initial state is:  (0.36089720128906105, -0.024543692606170286, -1.5707963267948966)\n",
      "In 69 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 69 th iteration, the robot moved  0.01190751156676062  in x direction\n",
      "In 70 th iteration the initial state is:  (0.3730146992825691, -0.049087385212340545, -1.5707963267948966)\n",
      "In 70 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 70 th iteration, the robot moved  0.01228368911790989  in x direction\n",
      "In 71 th iteration the initial state is:  (0.3849701255500751, -0.0736310778185108, -1.5707963267948966)\n",
      "In 71 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 71 th iteration, the robot moved  0.012662455655110039  in x direction\n",
      "In 72 th iteration the initial state is:  (0.39675540351179367, -0.09817477042468106, -1.5707963267948966)\n",
      "In 72 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 72 th iteration, the robot moved  0.013044157459936923  in x direction\n",
      "In 73 th iteration the initial state is:  (0.40836207738390173, -0.12271846303085132, -1.5707963267948966)\n",
      "In 73 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 73 th iteration, the robot moved  -0.10743342617652485  in x direction\n",
      "In 74 th iteration the initial state is:  (0.3170084247139796, 0.07363107781851075, -1.5707963267948966)\n",
      "In 74 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 74 th iteration, the robot moved  0.010402450399493501  in x direction\n",
      "In 75 th iteration the initial state is:  (0.32970015647990175, 0.04908738521234049, -1.5707963267948966)\n",
      "In 75 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 75 th iteration, the robot moved  0.010769443830668024  in x direction\n",
      "In 76 th iteration the initial state is:  (0.3422588232119126, 0.02454369260617023, -1.5707963267948966)\n",
      "In 76 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 76 th iteration, the robot moved  0.011137895145965082  in x direction\n",
      "In 77 th iteration the initial state is:  (0.35467762349620224, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 77 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 77 th iteration, the robot moved  0.011508028120799763  in x direction\n",
      "In 78 th iteration the initial state is:  (0.3669494697992874, -0.024543692606170286, -1.5707963267948966)\n",
      "In 78 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 78 th iteration, the robot moved  0.01188009340644225  in x direction\n",
      "In 79 th iteration the initial state is:  (0.3790669677927954, -0.049087385212340545, -1.5707963267948966)\n",
      "In 79 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 79 th iteration, the robot moved  0.01225437080522318  in x direction\n",
      "In 80 th iteration the initial state is:  (0.3910223940603014, -0.0736310778185108, -1.5707963267948966)\n",
      "In 80 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 80 th iteration, the robot moved  0.01263117176747297  in x direction\n",
      "In 81 th iteration the initial state is:  (0.40280767202202, -0.09817477042468106, -1.5707963267948966)\n",
      "In 81 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 81 th iteration, the robot moved  0.013010842137063161  in x direction\n",
      "In 82 th iteration the initial state is:  (0.41441434589412807, -0.12271846303085132, -1.5707963267948966)\n",
      "In 82 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 82 th iteration, the robot moved  -0.10715012140864211  in x direction\n",
      "In 83 th iteration the initial state is:  (0.32306069322420594, 0.07363107781851075, -1.5707963267948966)\n",
      "In 83 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 83 th iteration, the robot moved  0.010381605073483069  in x direction\n",
      "In 84 th iteration the initial state is:  (0.3357524249901281, 0.04908738521234049, -1.5707963267948966)\n",
      "In 84 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 84 th iteration, the robot moved  0.010746942937543302  in x direction\n",
      "In 85 th iteration the initial state is:  (0.3483110917221389, 0.02454369260617023, -1.5707963267948966)\n",
      "In 85 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 85 th iteration, the robot moved  0.011113674608949298  in x direction\n",
      "In 86 th iteration the initial state is:  (0.3607298920064286, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 86 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 86 th iteration, the robot moved  0.011482023553211818  in x direction\n",
      "In 87 th iteration the initial state is:  (0.3730017383095137, -0.024543692606170286, -1.5707963267948966)\n",
      "In 87 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 87 th iteration, the robot moved  0.011852240080175935  in x direction\n",
      "In 88 th iteration the initial state is:  (0.38511923630302175, -0.049087385212340545, -1.5707963267948966)\n",
      "In 88 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 88 th iteration, the robot moved  0.01222460361686628  in x direction\n",
      "In 89 th iteration the initial state is:  (0.39707466257052776, -0.0736310778185108, -1.5707963267948966)\n",
      "In 89 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 89 th iteration, the robot moved  0.012599425202005854  in x direction\n",
      "In 90 th iteration the initial state is:  (0.40885994053224634, -0.09817477042468106, -1.5707963267948966)\n",
      "In 90 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 90 th iteration, the robot moved  0.012977050229093567  in x direction\n",
      "In 91 th iteration the initial state is:  (0.4204666144043544, -0.12271846303085132, -1.5707963267948966)\n",
      "In 91 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 91 th iteration, the robot moved  -0.10686289174870889  in x direction\n",
      "In 92 th iteration the initial state is:  (0.3291129617344323, 0.07363107781851075, -1.5707963267948966)\n",
      "In 92 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 92 th iteration, the robot moved  0.010360379470915948  in x direction\n",
      "In 93 th iteration the initial state is:  (0.3418046935003544, 0.04908738521234049, -1.5707963267948966)\n",
      "In 93 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 93 th iteration, the robot moved  0.010724048385593266  in x direction\n",
      "In 94 th iteration the initial state is:  (0.35436336023236525, 0.02454369260617023, -1.5707963267948966)\n",
      "In 94 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 94 th iteration, the robot moved  0.0110890469797853  in x direction\n",
      "In 95 th iteration the initial state is:  (0.3667821605166549, -2.7755575615628914e-17, -1.5707963267948966)\n",
      "In 95 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 95 th iteration, the robot moved  0.011455598400911704  in x direction\n",
      "In 96 th iteration the initial state is:  (0.37905400681974005, -0.024543692606170286, -1.5707963267948966)\n",
      "In 96 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 96 th iteration, the robot moved  0.01182395260822422  in x direction\n",
      "In 97 th iteration the initial state is:  (0.3911715048132481, -0.049087385212340545, -1.5707963267948966)\n",
      "In 97 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 97 th iteration, the robot moved  0.012194388643206544  in x direction\n",
      "In 98 th iteration the initial state is:  (0.4031269310807541, -0.0736310778185108, -1.5707963267948966)\n",
      "In 98 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 98 th iteration, the robot moved  0.012567217121580487  in x direction\n",
      "In 99 th iteration the initial state is:  (0.41491220904247267, -0.09817477042468106, -1.5707963267948966)\n",
      "In 99 th iteration the chosen action is:  (-0.024543692606170259, 0.0)\n",
      "In 99 th iteration, the robot moved  0.012942782973820677  in x direction\n",
      "In 100 th iteration the initial state is:  (0.42651888291458073, -0.12271846303085132, -1.5707963267948966)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 100 th iteration the chosen action is:  (0.19634954084936207, 0.0)\n",
      "In 100 th iteration, the robot moved  -0.10657174771790245  in x direction\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183a7f12e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183a388198>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TIMESTEPS = 100\n",
    "xs = []\n",
    "a1s = []\n",
    "a2s = []\n",
    "steps = []\n",
    "dx = 0\n",
    "robot = ThreeLinkRobot()\n",
    "for i in range(TIMESTEPS):\n",
    "\n",
    "    # rollout\n",
    "    state = robot.state\n",
    "    print('In', i+1, 'th iteration the initial state is: ', state)\n",
    "    old_x = robot.x\n",
    "    action = agent.choose_action(robot, state)\n",
    "    print('In', i+1, 'th iteration the chosen action is: ', action)\n",
    "    robot.move(action=action)\n",
    "    new_x = robot.x\n",
    "    print('In', i+1, 'th iteration, the robot moved ', new_x - old_x, ' in x direction')\n",
    "    dx += (new_x-old_x)\n",
    "\n",
    "    # add values to lists\n",
    "    xs.append(dx)\n",
    "    a1s.append(robot.a1)\n",
    "    a2s.append(robot.a2)\n",
    "    steps.append(i)\n",
    "\n",
    "# plotting\n",
    "make_graphs(xs,a1s,a2s,steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI CartPole "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPISODES = 1000\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "# agent.load(\"./save/cartpole-dqn.h5\")\n",
    "done = False\n",
    "batch_size = 32\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for time in range(500):\n",
    "        # env.render()\n",
    "        action = agent.act(state)\n",
    "        # print(f'action:{action}')\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        reward = reward if not done else -10\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, score: {}, e: {:.2}\"\n",
    "                  .format(e, EPISODES, time, agent.epsilon))\n",
    "            break\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "    # if e % 10 == 0:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
